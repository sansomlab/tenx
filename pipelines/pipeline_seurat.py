##############################################################################
#
#   Kennedy Institute of Rheumatology
#
#   $Id$
#
#   Copyright (C) 2018 Stephen Sansom
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
###############################################################################

"""===========================
Pipeline Seurat
===========================

:Author: Sansom lab
:Release: $Id$
:Date: |today|
:Tags: Python

Overview
========

This pipeline wraps the Satija lab's Seurat (http://satijalab.org/seurat/)
package using a set of Rscripts.

For key parameters a range of choices can be specified. The pipeline will
generate one report for each parameter combination, dispatching analyses
from multiple samples in parallel for execution on a HPC cluster.

The pipeline also performs cluster geneset enrichment analysis using the
"gsfisher" R package (http://github/sansomlab/gsfisher).

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_seurat.py config


Input files
-----------

The pipeline can be run either:
(A) starting from a suitable count matrix and metadata file (such as
the output of pipeline_cellranger.py) or
(B) starting from a saved seurat object. This is useful for analysing
an object to which reduced dimensions from another method (e.g. zinbwave)
have been added.

(A) Starting from a processed tenx count matrix (and a metadata.tsv file).

Typically involves linking "dataset.dir" subfolders from a
pipeline_cellranger.py run.

A folder containing the expression matrix (market exchange format)
and metadata.tsv file should be linked into a "data.dir" subfolder.
The folder names must end with ".dir".

e.g.

$ ls data.dir
agg.dir               d1_control_mono.dir  d2_butyrate_mono.dir
d1_butyrate_mono.dir  d1_tmp195_mono.dir   d2_control_mono.dir

$ ls data.dir/agg.dir/
barcodes.tsv  genes.tsv  matrix.mtx  metadata.tsv

(B) Starting from a saved seurat object.

The pipeline can run downstream analysis on a saved seurat object (RDS
format) on which qc, data normalisation, selection of variable genes and
dimension reduction has been performed.

Each sample should be placed (or linked) as a "begin.rds" file in a directory
ending with ".seurat.dir", e.g.

wildtype.seurat.dir/begin.rds
knockout.seurat.dir/begin.rds
aggregated.seurat.dir/begin.rds


Dependencies
------------

This pipeline requires:

* cgat-core: https://github.com/cgat-developers/cgat-core
* cellranger: https://support.10xgenomics.com/single-cell-gene-expression/
* picard tools (optional): https://broadinstitute.github.io/picard/
* R & various packages.
* Latex.


Pipeline output
===============

For each sample and each combination of paramters the following is generated
in the "report.dir" subfoler:

* A pdf summary report
* A pdf gene expression report (arbitrary sets of genes can be specified)
* An excel table of cluster marker genes
* An excel table of cluster-enriched genesets
* Optionally an excel table of genes differentially expressed within cluster
* Optionally an excel table of genesets enriched in amongst genes
differentially expressed within-cluster

Intermediate results files are also retained in the per-sample directories.

"""

from ruffus import *
from pathlib import Path
import sys
import os
import shutil
import glob
import sqlite3
import numpy as np
import pandas as pd
from scipy.stats.mstats import gmean
import cgatcore.experiment as E
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

# -------------------------- < parse parameters > --------------------------- #

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline.yml" % os.path.splitext(__file__)[0],
     "../pipeline.yml",
     "pipeline.yml"])

# set the location of the tenx code directory
if "tenx_dir" not in PARAMS.keys():
    PARAMS["tenx_dir"] = Path(__file__).parents[1]
else:
    raise ValueError("Could not set the location of the tenx code directory")


# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))


# ########################################################################### #
# ############ construct one seurat object per input matrix ################# #
# ########################################################################### #

# QC, normalisation and dimension reduction are performed on the object.

@transform("data.dir/*.dir",
           regex(r".*/(.*).dir"),
           r"\1.seurat.dir/begin.rds")
def beginSeurat(infile, outfile):
    '''Setup the Seurat object and save it in RDS format.

       The Rscript "seurat_begin.R" reads in the raw data, performs
       QC filtering, removal of unwanted varation, identification of
       variable genes and PCA-based dimension reduction.
    '''

    outdir = outfile.split("/")[0]

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    sample_name = infile.split("/")[-1].split(".")[0]

    job_memory = "20G"
    job_threads = PARAMS["resources_numcores"]

    log_file = outfile.replace(".rds", ".log")
    metadata = os.path.join(infile, "metadata.tsv")

    if PARAMS["subsetcells_active"]:

        cells_to_use = PARAMS["subsetcells_" + sample_name]

        if PARAMS["subsetcells_type"] == "barcode_list":

            if not os.path.exists(cells_to_use) or cells_to_use == "use.all":
                raise ValueError("Invalid cell subsetting parameter"
                                 " specification")

            subset = '''--subsetcells=%(cells_to_use)s
                     ''' % locals()

        elif PARAMS["subsetcells_type"] == "factor":

            subset_factor = PARAMS["subsetcells_factor"]

            subset = '''--subsetfactor=%(subset_factor)s
                        --subsetlevel=%(cells_to_use)s
                     ''' % locals()

        else:
            raise ValueError("Unknown type of subsetting requested")

    else:
        subset = ""

    if ( os.path.isfile(PARAMS["cellcycle_sgenes"]) and
         os.path.isfile(PARAMS["cellcycle_g2mgenes"]) ):

        cell_cycle_genes = '''--sgenes=%(cellcycle_sgenes)s
                              --g2mgenes=%(cellcycle_g2mgenes)s
                           ''' % PARAMS

    else:
        cell_cycle_genes = ""


    if PARAMS["regress_cellcycle"] != "none":
        cell_cycle_regress = '''--cellcycle=%(regress_cellcycle)s
                             ''' % PARAMS
    else:
        cell_cycle_regress = ""

    # Turn Python boolean into R logical
    downsamplecells = str(PARAMS["qc_downsamplecells"]).upper()

    statement = '''Rscript %(tenx_dir)s/R/seurat_begin.R
                   --tenxdir=%(infile)s
                   --project=%(sample_name)s
                   --outdir=%(outdir)s
                   --groupby=%(qc_groupby)s
                   --mingenes=%(qc_initial_mingenes)s
                   --mincells=%(qc_mincells)s
                   --qcmingenes=%(qc_mingenes)s
                   --qcmaxpercentmito=%(qc_maxpercentmito)s
                   --metadata=%(metadata)s
                   --downsamplecells=%(downsamplecells)s
                   --latentvars=%(regress_latentvars)s
                   --modeluse=%(regress_modeluse)s
                   --vargenesmethod=%(vargenes_method)s
                   --topgenes=%(vargenes_topgenes)s
                   --sdcutoff=%(vargenes_sdcutoff)s
                   --xlowcutoff=%(vargenes_xlowcutoff)s
                   --xhighcutoff=%(vargenes_xhighcutoff)s
                   --jackstrawnumreplicates=%(dimreduction_jackstraw_n_replicate)s
                   --numcores=12
                   --plotdirvar=sampleDir
                   %(subset)s
                   %(cell_cycle_genes)s
                   %(cell_cycle_regress)s
                   &> %(log_file)s
                '''

    P.run(statement)



# ########################################################################### #
# ############ Begin per-parameter combination analysis runs ################ #
# ########################################################################### #

# For each sample, one run will be performed for each combination
# of the following key parameter choices (as defined in the "runspecs"):
#
# * cluster resolution
# * cluster algorithm
# * number of PCA components
# * differential expression algorithm

def genClusterJobs():
    '''
    Generate cluster jobs with all paramter combinations.
    '''

    resolutions_str = str(PARAMS["runspecs_cluster_resolutions"])
    resolutions = resolutions_str.strip().replace(" ", "").split(",")

    algos_str = str(PARAMS["runspecs_cluster_algorithms"])
    algos = algos_str.strip().replace(" ", "").split(",")

    tests = str(
        PARAMS["runspecs_de_tests"]).strip().replace(" ", "").split(",")

    if PARAMS["runspecs_skip"] is not None:
        skip = PARAMS["seurat_skip"].strip().replace(" ", "").split(",")
    else:
        skip = []

    pcs_str = str(PARAMS["runspecs_n_components"])
    pcs = pcs_str.strip().replace(" ", "").split(",")


    samples = glob.glob("*.seurat.dir")

    for sample in samples:
        for pca in pcs:
            for resolution in resolutions:
                for algorithm in algos:
                    for test in tests:
                        infile = os.path.join(sample, "begin.rds")
                        spec = "_".join([pca, resolution, algorithm, test])
                        outdir = spec
                        subdir = "cluster.dir"
                        outname = "cluster.sentinel"
                        if(os.path.join(sample, outdir) in skip):
                            continue
                        outfile = os.path.join(sample, outdir, subdir, outname)
                        yield [infile, outfile]


@follows(beginSeurat)
@files(genClusterJobs)
def cluster(infile, outfile):
    '''Perform clustering on a saved seurat object.

       The single-cells are clustered using the given number of PCA components,
       resolution and alogorithm.

       The number of clusters is written to "nclusters.txt".
    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.makedirs(outdir)

    outname = os.path.basename(outfile)
    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    reductiontype = PARAMS["dimreduction_method"]

    if(components=="sig"):
        comp="--usesigcomponents=TRUE"
    else:
        comp="--components=%(components)s" % locals()

    job_memory = "20G"

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/seurat_cluster.R
                   --seuratobject=%(infile)s
                   %(comp)s
                   --resolution=%(resolution)s
                   --algorithm=%(algorithm)s
                   --outdir=%(outdir)s
                   --reductiontype=%(reductiontype)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


# ########################################################################### #
# ############### compare the clusters across resolutions ################### #
# ########################################################################### #


@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/cluster.dir/clustree.sentinel")
def clustree(infile, outfile):
    '''

    '''

    indir = os.path.dirname(infile)
    outdir = os.path.dirname(outfile)

    resolutions_str = str(PARAMS["runspecs_cluster_resolutions"])
    resolutions = resolutions_str.strip().replace(" ", "").split(",")

    cluster_ids = os.path.join(indir, "cluster_ids.rds")

    sampleDir = Path(cluster_ids).parts[0]
    runDir = Path(cluster_ids).parts[1]
    print("********")
    print(runDir)

    pcs, res, algo, de = runDir.split("_")

    id_files = [ os.path.join(sampleDir,
                              "_".join([pcs,r,algo,de]),
                              "cluster.dir",
                              "cluster_ids.rds")
                 for r in resolutions ]

    res_str = ",".join(resolutions)
    id_files_str = ",".join(id_files)

    print(id_files)

    log_file = outfile.replace("sentinel","log")

    statement = '''Rscript %(tenx_dir)s/R/seurat_clustree.R
                   --resolutions=%(res_str)s
                   --clusteridfiles=%(id_files_str)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)

# ########################################################################### #
# ############### tSNE analysis and related plots ########################### #
# ########################################################################### #

@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/tsne.dir/tsne.sentinel")
def tSNE(infile, outfile):
    '''
    Run the tSNE analysis on a saved seurat object.

    A range of different perplexity choices can be specified.
    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    seurat_dir = Path(outdir).parents[1]
    seurat_object = os.path.join(seurat_dir, "begin.rds")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    reductiontype = PARAMS["dimreduction_method"]

    job_memory = "20G"

    perplexity_values = set(
        PARAMS["tsne_perplexities"].strip().replace(" ", "").split(",") +
        [PARAMS["tsne_perplexity"]])

    statements = []

    tenx_dir = PARAMS["tenx_dir"]
    tsne_fast = PARAMS["tsne_fast"]
    max_iter = PARAMS["tsne_maxiter"]

    if(components=="sig"):
        comp="--usesigcomponents=TRUE"
    else:
        comp="--components=%(components)s" % locals()

    for p in perplexity_values:

        outname = outfile.replace(".sentinel", "." + str(p) + ".txt")
        logfile = outname.replace(".txt", ".log")

        statements.append('''Rscript %(tenx_dir)s/R/seurat_tsne.R
                             --seuratobject=%(seurat_object)s
                             --clusterids=%(cluster_ids)s
                             %(comp)s
                             --reductiontype=%(reductiontype)s
                             --perplexity=%(p)s
                             --maxiter=%(max_iter)s
                             --fast=%(tsne_fast)s
                             --outfile=%(outname)s
                             &> %(logfile)s
                          ''' % locals())
    P.run(statements)
    IOTools.touch_file(outfile)


@transform(tSNE,
           regex(r"(.*)/tsne.sentinel"),
           r"\1/plot.tsne.perplexities.sentinel")
def plotTSNEPerplexities(infile, outfile):
    '''
    Visualise effect of the perplexity hyperparameter on tSNE layout.

    A page containing side-by-side plots of the different perplexity
    choices is produced.
    '''

    # concatenate all the tSNE results into a single table
    outdir = os.path.dirname(outfile)
    perplexities = PARAMS["tsne_perplexities"]
    perplexity_values = perplexities.strip().replace(" ", "").split(",")

    frames = []

    for p in perplexity_values:

        tsne_table = infile.replace("sentinel", str(p) + ".txt")

        # Perplexity values that are too high are silently skipped
        # in the previous task.
        if os.path.exists(tsne_table):

            data = pd.read_csv(tsne_table, sep="\t")
            data["perplexity"] = p
            frames.append(data)

    long = pd.concat(frames)

    long_table = infile.replace(".sentinel", ".perplexity.txt")
    long.to_csv(long_table, sep="\t", header=True, index=False)

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/plot_tsne_hyperparameters.R
                   --table=%(long_table)s
                   --shapefactor=%(plot_shape)s
                   --colorfactor=cluster
                   --hyperparameter=perplexity
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --plotdirvar=tsneDir
                   --outdir=%(outdir)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


@transform(tSNE,
           regex(r"(.*)/tsne.sentinel"),
           r"\1/plot.rdims.tsne.factor.sentinel")
def plotTSNEFactors(infile, outfile):
    '''
    Visualise factors of interest on tSNE plots

    Make tSNE plots coloring cells by e.g. QC variables, batch and cluster.
    Plots for cluster, seq_id and agg_id are made when these factors
    have more than one level. The shape factor will be used for all plots.

    One additional plot will be made for each coloring factor specifed.
    '''

    outdir = os.path.dirname(outfile)

    job_memory = "20G"

    tsne_table = infile.replace(
        "sentinel", str(PARAMS["tsne_perplexity"]) + ".txt")

    color_factors = ["cluster"]

    if PARAMS["plot_qcvars"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_qcvars"].split(",")]

    if PARAMS["plot_groups"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_groups"].split(",")]

    if PARAMS["plot_subgroup"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_subgroup"].split(",")]

    # ensure list is unique whilst preserving order.
    color_factors = list(dict.fromkeys(color_factors))

    color_factors = "--colorfactors=" + ",".join(color_factors)

    if PARAMS["plot_shape"] is not None:
        shape_factors = "--shapefactor=%(plot_shape)s" % PARAMS
    else:
        shape_factors = ""

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/plot_rdims_factor.R
                   --method=tsne
                   --table=%(tsne_table)s
                   --rdim1=tSNE_1
                   --rdim2=tSNE_2
                   %(shape_factors)s
                   %(color_factors)s
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --outdir=%(outdir)s
                   --plotdirvar=tsneDir
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


@transform(tSNE,
           regex(r"(.*)/tsne.dir/tsne.sentinel"),
           r"\1/genelists.dir/plot.rdims.genes.sentinel")
def plotTSNEGenes(infile, outfile):
    '''
    Visualise gene expression levels on tSNE plots.

    The @data slot of the seurat object is used.
    '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.mkdir(outdir)

    sample_dir = str(Path(outdir).parents[1])
    seurat_object = os.path.join(sample_dir, "begin.rds")

    tex_path = os.path.join(outdir, "plot.rdims.known.genes.tex")

    if PARAMS["exprsreport_genelists"]:
        genelists = glob.glob(
            os.path.join(PARAMS["exprsreport_genelist_dir"], "*.txt"))

        job_memory = "20G"

        tsne_table = infile.replace(
            "sentinel", str(PARAMS["tsne_perplexity"]) + ".txt")

        for genelist in genelists:

            fname = "plot.rdims.genes." + os.path.basename(genelist) + ".log"
            logfile = os.path.join(outdir, fname)

            if PARAMS["plot_shape"] is not None:
                shape = "--shapefactor=%(plot_shape)s" % PARAMS
            else:
                shape = ""

            statement = '''Rscript %(tenx_dir)s/R/plot_rdims_gene.R
                           --method=tsne
                           --table=%(tsne_table)s
                           --seuratobject=%(seurat_object)s
                           --rdim1=tSNE_1
                           --rdim2=tSNE_2
                           %(shape)s
                           --genetable=%(genelist)s
                           --pointsize=%(plot_pointsize)s
                           --pointalpha=%(plot_pointalpha)s
                           --outdir=%(outdir)s
                           --plotdirvar=genelistsDir
                           &> %(logfile)s
                       '''
            P.run(statement)

        # prepare a summary tex snippet for inclusion in the report.

        with(open(tex_path, "w")) as tex:

            for genelist in genelists:

                texf = os.path.join(
                    outdir,
                    "plot.rdims.genes." +
                    os.path.basename(genelist).replace(".txt", ""))

                gsname = os.path.basename(
                    genelist)[:-len(".txt")].replace("_", "\\_")

                tex.write(
                    "\\subsection{Expression of known genes: %s}\n" % gsname)
                tex.write(
                    "\\input{%(texf)s}\n" % locals())

            tex.write("\n")

    else:

        with(open(tex_path, "w")) as tex:

            tex.write("No genelists were specified.\n")
            tex.write("\n")

    IOTools.touch_file(outfile)


# ########################################################################### #
# ############### UMAP analysis and related plots ########################### #
# ########################################################################### #

@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/umap.dir/umap.sentinel")
def UMAP(infile, outfile):
    '''
    Run the UMAP analysis on a saved seurat object.
    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    cluster_ids = infile.replace(".sentinel","_ids.rds")

    seurat_dir = Path(outdir).parents[1]
    seurat_object = os.path.join(seurat_dir, "begin.rds")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    reductiontype = PARAMS["dimreduction_method"]

    if(components=="sig"):
        comp="--usesigcomponents=TRUE"
    else:
        comp="--components=%(components)s" % locals()

    job_memory = "20G"

    tenx_dir = PARAMS["tenx_dir"]

    umap_nneighbors = PARAMS["umap_nneighbors"]
    umap_mindist = PARAMS["umap_mindist"]
    umap_metric = PARAMS["umap_metric"]

    outname = outfile.replace(".sentinel", ".txt")
    logfile = outname.replace(".txt", ".log")

    statement = '''Rscript %(tenx_dir)s/R/seurat_umap.R
                             --seuratobject=%(seurat_object)s
                             --clusterids=%(cluster_ids)s
                             %(comp)s
                             --reductiontype=%(reductiontype)s
                             --nneighbors=%(umap_nneighbors)s
                             --mindist=%(umap_mindist)s
                             --metric=%(umap_metric)s
                             --outfile=%(outname)s
                             &> %(logfile)s
                          ''' % locals()

    P.run(statement)
    IOTools.touch_file(outfile)


@transform(UMAP,
           regex(r"(.*)/umap.sentinel"),
           r"\1/plot.rdims.umap.factor.sentinel")
def plotUMAPFactors(infile, outfile):
    '''
    Visualise the clusters on the UMAP projection
    '''

    outdir = os.path.dirname(outfile)
    job_memory = "20G"

    umap_table = infile.replace(
        "sentinel", "txt")

    color_factors = ["cluster"]

    if PARAMS["plot_qcvars"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_qcvars"].split(",")]

    if PARAMS["plot_groups"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_groups"].split(",")]

    if PARAMS["plot_subgroup"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_subgroup"].split(",")]

    # ensure list is unique whilst preserving order.
    color_factors = list(dict.fromkeys(color_factors))

    color_factors = "--colorfactors=" + ",".join(color_factors)


    if PARAMS["plot_shape"] is not None:
        shape_factors = "--shapefactor=%(plot_shape)s" % PARAMS
    else:
        shape_factors = ""

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/plot_rdims_factor.R
                   --method=umap
                   --table=%(umap_table)s
                   --rdim1=UMAP1
                   --rdim2=UMAP2
                   %(shape_factors)s
                   %(color_factors)s
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --outdir=%(outdir)s
                   --plotdirvar=umapDir
                   &> %(log_file)s
                '''

    P.run(statement)
    IOTools.touch_file(outfile)

# ########################################################################### #
# ############################## Diffusion maps ############################# #
# ########################################################################### #

@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/diffmap.dir/dm.sentinel")
def diffusionMap(infile, outfile):
    '''
    Run the diffusion map analysis on a saved seurat object.
    '''

    outdir = os.path.dirname(outfile)
    cluster_ids = infile.replace(".sentinel","_ids.rds")

    seurat_dir = Path(outdir).parents[1]
    seurat_object = os.path.join(seurat_dir, "begin.rds")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    reductiontype = PARAMS["dimreduction_method"]
    if(components=="sig"):
        comp="--usesigcomponents=TRUE"
    else:
        comp="--components=%(components)s" % locals()

    if PARAMS["diffmap_usegenes"]:
        usegenes="--usegenes=TRUE"
    else:
        usegenes="--usegenes=FALSE"

    job_memory = "20G"

    tenx_dir = PARAMS["tenx_dir"]

    diffmap_maxdim = PARAMS["diffmap_maxdim"]

    outname = outfile.replace(".sentinel", ".txt")
    logfile = outname.replace(".txt", ".log")

    statement = '''Rscript %(tenx_dir)s/R/seurat_dm.R
                             --seuratobject=%(seurat_object)s
                             --clusterids=%(cluster_ids)s
                             %(usegenes)s
                             %(comp)s
                             --reductiontype=%(reductiontype)s
                             --maxdim=%(diffmap_maxdim)s
                             --outfile=%(outname)s
                             --outdir=%(outdir)s
                             --plotdirvar=diffmapDir
                             &> %(logfile)s
                          ''' % locals()

    P.run(statement)
    IOTools.touch_file(outfile)



# ########################################################################### #
# ################# plot per-cluster summary statistics ##################### #
# ########################################################################### #

@transform(tSNE,
           regex(r"(.*)/tsne.dir/tsne.sentinel"),
           r"\1/group.numbers.dir/plot.group.numbers.sentinel")
def plotGroupNumbers(infile, outfile):
    '''
    Plot statistics on cells by group, e.g. numbers of cells per cluster.
    '''

    outdir = os.path.dirname(outfile)

    sample_dir = str(Path(outdir).parents[1])
    seurat_object = os.path.join(sample_dir, "begin.rds")

    job_memory = "20G"

    tsne_table = infile.replace(
        "sentinel", str(PARAMS["tsne_perplexity"]) + ".txt")

    if PARAMS["plot_subgroup"] is not None:
        subgroupfactor = "--subgroupfactor=%(plot_subgroup)s" % PARAMS
    else:
        subgroupfactor = ""

    if PARAMS["plot_groups"] is not None:
        plot_groups = [x.strip() for x in
                       PARAMS["plot_groups"].split(",")]

        if "cluster" not in plot_groups:
            plot_groups.append("cluster")

        plot_groups = ",".join(plot_groups)

    else:
        plot_groups = "cluster"

    groupfactors = "--groupfactors={}".format(plot_groups)

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/plot_group_numbers.R
                   --table=%(tsne_table)s
                   --seuratobject=%(seurat_object)s
                    %(groupfactors)s
                    %(subgroupfactor)s
                   --outdir=%(outdir)s
                   --plotdirvar=groupNumbersDir
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


# ########################################################################### #
# #################### Retrieve geneset annoations ########################## #
# ########################################################################### #

# Retrieve gene annotations and KEGG pathways.
#
# The "ensembl.to.entrez.txt.gz" table is needed for:
# - adding ensembl gene_ids to the findMarkers results table if s@misc$gene
#   is not set
# - translating ensembl gene_ids to entrez gene_ids for the geneset
#   analysis

@follows(mkdir("annotation.dir"))
@files(None, "annotation.dir/genesets.sentinel")
def getGenesetAnnotations(infile, outfile):
    '''Get mappings between Ensembl gene_ids and (i) Entrez ids
       and (ii) KEGG pathways.
    '''

    outdir = os.path.dirname(outfile)

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/fetch_geneset_annotations.R
                 --ensemblversion=%(annotation_ensembl_release)s
                 --species=%(annotation_species)s
                 --outdir=%(outdir)s
                 &> %(log_file)s
              '''

    P.run(statement)

    IOTools.touch_file(outfile)


# ########################################################################### #
# ############# Cluster marker identification and visualisation ############# #
# ########################################################################### #

@follows(getGenesetAnnotations)
@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/cluster.markers.dir/findMarkers.sentinel")
def findMarkers(infile, outfile):
    '''
    Identification of cluster marker genes.

    This analysis is run in parallel for each cluster.
    '''

    indir = os.path.dirname(infile)
    outdir = os.path.dirname(outfile)

    cluster_ids = infile.replace(".sentinel","_ids.rds")

    with open(os.path.join(indir, "nclusters.txt"), "r") as nclust:
        nclusters = nclust.readline().strip()

    seurat_object = os.path.join(Path(outdir).parents[1],
                                 "begin.rds")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    threshuse = PARAMS["findmarkers_threshuse"]
    minpct = PARAMS["findmarkers_minpct"]

    if PARAMS["findmarkers_conserved"]:
        conservedfactor = PARAMS["findmarkers_conserved_factor"]
        conservedpadj = PARAMS["findmarkers_conserved_padj"]
        conserved_options = '''--conservedfactor=%(conservedfactor)s
            --conservedpadj=%(conservedpadj)s
        '''
    else:
        conserved_options = ""

    job_memory = "30G"

    tenx_dir = PARAMS["tenx_dir"]
    statements = []

    for i in range(0, int(nclusters)):

        logfile = outfile.replace(".sentinel", "." + str(i) + ".log")
        statements.append('''Rscript %(tenx_dir)s/R/seurat_FindMarkers.R
                   --seuratobject=%(seurat_object)s
                   --clusterids=%(cluster_ids)s
                   --cluster=%(i)s
                   --testuse=%(test)s
                   --minpct=%(minpct)s
                   --mindiffpct=-Inf
                   --threshuse=%(threshuse)s
                   %(conserved_options)s
                   --annotation=annotation.dir/ensembl.to.entrez.txt.gz
                   --outdir=%(outdir)s
                   &> %(logfile)s
                ''' % locals())

    P.run(statements)

    IOTools.touch_file(outfile)


@transform(findMarkers,
           regex(r"(.*)/findMarkers.sentinel"),
           r"\1/summariseMarkers.sentinel")
def summariseMarkers(infile, outfile):
    '''
    Make summary tables and plots of cluster marker genes.

    The per-cluster results files are aggregated. A heatmap of the top
    cluster markers is generated. A summary excel file is generated.
    Tables for geneset enrichment testing are prepared.
    '''

    outdir = os.path.dirname(outfile)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    seurat_object = os.path.join(Path(outdir).parents[1],
                               "begin.rds")


    job_memory = "50G"

    log_file = outfile.replace(".sentinel", ".log")

    # make sumamary tables and plots of the differentially expressed genes
    statement = '''Rscript %(tenx_dir)s/R/seurat_summariseMarkers.R
                   --seuratobject=%(seurat_object)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


@transform(summariseMarkers,
           regex(r"(.*)/cluster.markers.dir/summariseMarkers.sentinel"),
           r"\1/cluster.marker.de.plots.dir/characteriseClusterMarkers.tex")
def characteriseClusterMarkers(infile, outfile):
    '''
    Characterise cluster marker genes.

    Diagnostic summary plots of differentially expressed genes
    and violin plots of cluster marker gene expression are generated.

    Parallelised per-cluster.
    '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.mkdir(outdir)

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.txt.gz")


    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    seurat_object = os.path.join(Path(outdir).parents[1],
                               "begin.rds")

    job_memory = "10G"

    # not all clusters may have degenes
    degenes = pd.read_csv(marker_table, sep="\t")
    clusters = [x for x in set(degenes["cluster"].values)]

    tenx_dir = PARAMS["tenx_dir"]

    statements = []
    tex = []
    for i in clusters:

        log_file = outfile[:-len(".tex")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(tenx_dir)s/R/seurat_characteriseClusterDEGenes.R
                    --degenes=%(marker_table)s
                    --seuratobject=%(seurat_object)s
                    --clusterids=%(cluster_ids)s
                    --cluster=%(i)s
                    --outdir=%(outdir)s
                    --useminfc=TRUE
                    --plotdirvar=clusterMarkerDEPlotsDir
                    &> %(log_file)s
                    ''' % locals()

        cluster_tex_file = ".".join(["characterise.degenes", str(i), "tex"])
        tex.append("\\input{\\clusterMarkerDEPlotsDir/" + cluster_tex_file + "}")
        statements.append(statement)

    P.run(statements)

    with open(outfile, "w") as out_tex:
        for line in tex:
            out_tex.write(line + "\n")


@transform(summariseMarkers,
           regex(r"(.*)/cluster.markers.dir/(.*).sentinel"),
           r"\1/cluster.marker.de.plots.dir/plotMarkerNumbers.sentinel")
def plotMarkerNumbers(infile, outfile):
    '''
    Summarise the numbers of per-cluster marker genes.
    '''

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.txt.gz")

    outdir = os.path.dirname(outfile)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    job_memory = "10G"

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/seurat_summariseMarkerNumbers.R
                   --degenes=%(marker_table)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   --minfc=2
                   --minpadj=0.05
                   --plotdirvar=clusterMarkerDEPlotsDir
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


@follows(summariseMarkers)
@transform(tSNE,
           regex(r"(.*)/tsne.dir/tsne.sentinel"),
           r"\1/cluster.marker.tsne.plots.dir/plot.rdims.markers.sentinel")
def plotTSNEMarkers(infile, outfile):
    '''
    Visualise expression of discovered markers on tSNE plots.

    An effort is made to prioritise the strongest cluster markers
    based on significance, expression frequency, expression level
    and fold change.
    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    seurat_object = os.path.join(Path(outdir).parents[1],
                                 "begin.rds")

    marker_summary_file = os.path.join(Path(outdir).parents[0],
                                       "cluster.markers.dir",
                                       "markers.summary.table.txt.gz")

    data = pd.read_csv(marker_summary_file, sep="\t")

    def _filterAndScore(data):
        # filter for strong cluster markers
        data = data[(data["p.adj"] < 0.01) &
                    (data["avg_logFC"].abs() > np.log(2)) &
                    (data["cluster_mean"] > 2) &
                    (data["pct.1"] > 0.25)]

        # compute a score based on all factors of interest.
        # here we use the product of the rank-normalised values
        # for fold change, expression level and adjusted p-value.
        # the aim is to give "better" markers higher scores.
        pscore = [1 - x for x in data["p.adj"].values]
        fscore = [np.exp(np.abs(x)) for x in data["avg_logFC"].values]
        escore = [np.log2(x) for x in data["cluster_mean"].values]

        # construct a matrix of the scores and take the geometric mean.
        temp = np.matrix([pscore,
                          fscore,
                          escore])

        data["score"] = np.squeeze(np.asarray(gmean(temp)))

        # keep only the best record for each gene
        data = data.sort_values(["score"], ascending=False)
        data = data.drop_duplicates(subset="gene_id", keep="first")

        # re-sort by cluster and then score
        data = data.sort_values(["cluster", "score"], ascending=[True, False])

        return data

    # define some helper functions..
    def _skimMarkers(data, n=40):
        # ensure we are ranked by cluster and score, best genes first.
        data = data.sort_values(["cluster", "score"], ascending=[True, False])

        # add the per cluster rankings
        data["grank"] = data.groupby(["cluster"]).cumcount()+1

        # de-duplicate keeping the marker for the cluster where
        # it has the best ranking.
        data = data.sort_values(["grank"], ascending=True)
        data = data.drop_duplicates(subset="gene_id", keep="first")

        # reorder and take the n best markers per cluster.
        data = data.sort_values(["cluster", "score"], ascending=[True, False])
        data = data.groupby("cluster").head(n)

        return data

    def _addGeneName(d):
        d["gene_name"] = d["gene"] + " (" + d["type"] + "; cluster " + \
                         d["cluster"].astype(str) + ")"
        return d

    def _report(d, name="none", seurat_object=seurat_object):

        # write the markers out to a table
        file_name = ".".join(["top", name, "cluster.markers.txt"])
        markers_file = os.path.join(outdir, file_name)
        d.to_csv(markers_file, header=True, sep="\t")

        job_memory = "20G"

        log_name = ".".join(["plot.rdims.top", name, "cluster.markers.log"])
        log_file = os.path.join(outdir, log_name)

        tsne_table = infile.replace(
            "sentinel", str(PARAMS["tsne_perplexity"]) + ".txt")

        if(d.shape[0] > 0):

            if PARAMS["plot_shape"] != "":
                shape = "--shapefactor=%(plot_shape)s" % PARAMS
            else:
                shape = ""

            statement = '''Rscript %(tenx_dir)s/R/plot_rdims_gene.R
                           --method=tsne
                           --table=%(tsne_table)s
                           --seuratobject=%(seurat_object)s
                           --rdim1=tSNE_1
                           --rdim2=tSNE_2
                           %(shape)s
                           --genetable=%(markers_file)s
                           --pointsize=%(plot_pointsize)s
                           --pointalpha=%(plot_pointalpha)s
                           --outdir=%(outdir)s
                           --plotdirvar=clusterMarkerTSNEPlotsDir
                           &> %(log_file)s
                       '''
            P.run(statement)

        else:
            with(open(os.path.join(outdir, "plot.rdims.genes.top." + name +
                                   ".cluster.markers.tex"), "w")) as tex:

                tex.write("No marker genes passed criteria for plotting\n")

    # keep up to n entries per cluster
    # note that groupby preserves the ordering.
    positive_markers = data[data["avg_logFC"] > 0]
    positive_markers = _filterAndScore(positive_markers)
    positive_markers = _skimMarkers(positive_markers,
                                    PARAMS["exprsreport_n_positive"])
    positive_markers["type"] = "+ve"
    positive_markers = _addGeneName(positive_markers)
    _report(positive_markers, "positive")

    negative_markers = data[data["avg_logFC"] < 0]
    negative_markers = _filterAndScore(negative_markers)
    negative_markers = _skimMarkers(negative_markers,
                                    PARAMS["exprsreport_n_negative"])
    negative_markers["type"] = "-ve"
    negative_markers = _addGeneName(negative_markers)
    _report(negative_markers, "negative")

    IOTools.touch_file(outfile)


# ########################################################################### #
# ################# Within cluster between condition DE ##################### #
# ########################################################################### #

# Here genes differentially expressed between two conditions are identified
# at the cluster level.
#
# This analysis is optional.
#
# It is only run on samples prefixed with "all.", "agg." or "aligned."

@active_if(PARAMS["findmarkers_between"])
@follows(getGenesetAnnotations)
@transform(cluster,
           regex(r"(all.*|agg.*|aligned.*)/cluster.dir/cluster.sentinel"),
           r"\1/condition.markers.dir/findMarkersBetweenConditions.sentinel")
def findMarkersBetweenConditions(infile, outfile):
    '''
    Identification of genes differentially expressed within-cluster.

    The two conditions to compare must be specified in the configuration file.

    This analysis is run in parallel for each cluster.
    '''

    indir = os.path.dirname(infile)
    outdir = os.path.dirname(outfile)

    cluster_ids = infile.replace(".sentinel", "_ids.rds")

    with open(os.path.join(indir, "nclusters.txt"), "r") as nclust:
        nclusters = nclust.readline().strip()

    seurat_object = os.path.join(Path(outdir).parents[1],
                                 "begin.rds")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    threshuse = PARAMS["findmarkers_threshuse"]
    minpct = PARAMS["findmarkers_minpct"]

    job_memory = "20G"

    statements = []

    # need to generalise this...
    group_a = PARAMS["findmarkers_between_a"]
    group_b = PARAMS["findmarkers_between_b"]
    tenx_dir = PARAMS["tenx_dir"]
    testfactor = PARAMS["findmarkers_between_testfactor"]

    if PARAMS["findmarkers_conserved_between"]:
        conservedfactor = PARAMS["findmarkers_conserved_between_factor"]
        conservedpadj = PARAMS["findmarkers_conserved_between_padj"]
        conserved_options = '''--conservedfactor=%(conservedfactor)s
            --conservedpadj=%(conservedpadj)s
        '''
    else:
        conserved_options = ""

    for i in range(0, int(nclusters)):

        logfile = outfile.replace(".sentinel", "." + str(i) + ".log")
        statements.append('''Rscript %(tenx_dir)s/R/seurat_FindMarkers.R
                   --seuratobject=%(seurat_object)s
                   --clusterids=%(cluster_ids)s
                   --cluster=%(i)s
                   --testfactor=%(testfactor)s
                   --a=%(group_a)s
                   --b=%(group_b)s
                   --testuse=%(test)s
                   --threshuse=%(threshuse)s
                   --minpct=%(minpct)s
                   --mindiffpct=-Inf
                   --annotation=annotation.dir/ensembl.to.entrez.txt.gz
                   %(conserved_options)s
                   --outdir=%(outdir)s
                   &> %(logfile)s
                ''' % locals())

    P.run(statements)

    IOTools.touch_file(outfile)


@active_if(PARAMS["findmarkers_between"])
@transform(findMarkersBetweenConditions,
           regex(r"(.*)/findMarkersBetweenConditions.sentinel"),
           r"\1/summariseMarkersBetweenConditions.sentinel")
def summariseMarkersBetweenConditions(infile, outfile):
    '''
    Make summary tables and plots of within-cluster DE genes.

    The per-cluster results files are aggregated. A heatmap of the top
    cluster markers is generated. A summary excel file is generated.
    Tables for geneset enrichment testing are prepared.
    '''

    outdir = os.path.dirname(outfile)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    seurat_object = os.path.join(Path(outdir).parents[1],
                               "begin.rds")

    job_memory = "20G"

    testname = os.path.basename(outfile).split(".")[1]

    log_file = outfile.replace(".sentinel", ".log")

    # make sumamary tables and plots of the differentially expressed genes
    statement = '''Rscript %(tenx_dir)s/R/seurat_summariseMarkersBetween.R
                   --seuratobject=%(seurat_object)s
                   --testfactor=%(findmarkers_between_testfactor)s
                   --a=%(findmarkers_between_a)s
                   --b=%(findmarkers_between_b)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


@active_if(PARAMS["findmarkers_between"])
@transform(summariseMarkersBetweenConditions,
           regex(r"(.*)/condition.markers.dir/summariseMarkersBetweenConditions.sentinel"),
           r"\1/condition.marker.de.plots.dir/characteriseClusterMarkersBetween.tex")
def characteriseClusterMarkersBetweenConditions(infile, outfile):
    '''
    Characterise within-cluster DE genes.

    Diagnostic summary plots of differentially expressed genes
    and violin plots are generated.

    Parallelised per-cluster.
    '''

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.between." +
                                PARAMS["findmarkers_between_testfactor"] +
                                ".summary.table.txt.gz")

    outdir = os.path.dirname(outfile)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    seurat_object = os.path.join(Path(outdir).parents[1],
                               "begin.rds")

    job_memory = "10G"

    # not all clusters may have degenes
    degenes = pd.read_csv(marker_table, sep="\t")
    clusters = [x for x in set(degenes["cluster"].values)]

    tenx_dir = PARAMS["tenx_dir"]
    testfactor = PARAMS["findmarkers_between_testfactor"]
    a = PARAMS["findmarkers_between_a"]
    b = PARAMS["findmarkers_between_b"]

    statements = []
    tex = []
    for i in clusters:

        log_file = outfile[:-len(".tex")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(tenx_dir)s/R/seurat_characteriseClusterDEGenes.R
                    --degenes=%(marker_table)s
                    --seuratobject=%(seurat_object)s
                    --clusterids=%(cluster_ids)s
                    --cluster=%(i)s
                    --testfactor=%(testfactor)s
                    --a=%(a)s
                    --b=%(b)s
                    --useminfc=FALSE
                    --outdir=%(outdir)s
                    --plotdirvar=conditionMarkerDEPlotsDir
                    &> %(log_file)s
                    ''' % locals()

        cluster_tex_file = ".".join(["characterise.degenes", str(i),
                                     "between.tex"])

        tex.append("\\input{\\conditionMarkerDEPlotsDir/" + cluster_tex_file + "}")
        statements.append(statement)

    P.run(statements)

    with open(outfile, "w") as out_tex:
        for line in tex:
            out_tex.write(line + "\n")


@active_if(PARAMS["findmarkers_between"])
@transform(summariseMarkersBetweenConditions,
           regex(r"(.*)/condition.markers.dir/(.*).sentinel"),
           r"\1/condition.marker.de.plots.dir/plotMarkerNumbersBetween.sentinel")
def plotMarkerNumbersBetweenConditions(infile, outfile):
    '''
    Summarise the numbers of within-cluster DE genes.
    '''

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.between." +
                                PARAMS["findmarkers_between_testfactor"] +
                                ".summary.table.txt.gz")

    outdir = os.path.dirname(outfile)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    job_memory = "10G"

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/seurat_summariseMarkerNumbers.R
                   --degenes=%(marker_table)s
                   --clusterids=%(cluster_ids)s
                   --testfactor=%(findmarkers_between_testfactor)s
                   --a=%(findmarkers_between_a)s
                   --b=%(findmarkers_between_b)s
                   --minfc=2
                   --minpadj=0.05
                   --outdir=%(outdir)s
                   --plotdirvar=conditionMarkerDEPlotsDir
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


# ########################################################################### #
# ########### marker gene (and within cluster DE) analysis ################## #
# ########################################################################### #

@follows(characteriseClusterMarkers,
         plotMarkerNumbers,
         characteriseClusterMarkersBetweenConditions,
         plotMarkerNumbersBetweenConditions)
def markers():
    pass


# ########################################################################### #
# ######################### Geneset Analysis ################################ #
# ########################################################################### #

def parseGMTs():
    '''Helper function for parsing the list of GMT files'''

    gmts = [x for x in PARAMS.keys()
            if x.startswith("gmt_files_")]

    if len(gmts) > 0:
        gmt_files = ",".join([PARAMS[x] for x in gmts])

        gmt_names = ",".join([x.replace("gmt_files_", "")
                              for x in gmts])

    else:
        gmt_files = "none"
        gmt_names = "none"

    return gmt_names, gmt_files


# ------------------- < between cluster geneset analysis > ------------------ #

@follows(summariseMarkers)
@transform(findMarkers,
           regex(r"(.*)/cluster.markers.dir/.*.sentinel"),
           add_inputs(getGenesetAnnotations),
           r"\1/cluster.genesets.dir/genesetAnalysis.sentinel")
def genesetAnalysis(infiles, outfile):
    '''
    Naive geneset over-enrichment analysis of cluster marker genes.

    Testing is performed with the gsfisher package.

    GO categories and KEGG pathways are tested by default.

    Arbitrary sets of genes cat be supplied as GMT files
    (e.g. such as those from MSigDB).
    '''

    findMarkersLog, genesetAnno = infiles

    indir = os.path.dirname(findMarkersLog)

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.mkdir(outdir)


    anno = os.path.join(os.path.dirname(genesetAnno),
                        "ensembl.to.entrez.txt.gz")

    kegg_pathways = os.path.join(os.path.dirname(genesetAnno),
                                 "kegg_pathways.rds")

    gmt_names, gmt_files = parseGMTs()


    with open(os.path.join(Path(outdir).parents[0],
                           "cluster.dir",
                           "nclusters.txt"), "r") as nclust:
        nclusters = nclust.readline().strip()

    job_memory = "20G"

    statements = []

    species = PARAMS["annotation_species"]
    tenx_dir = PARAMS["tenx_dir"]

    for i in range(0, int(nclusters)):

        logfile = os.path.join(outdir, "geneset.analysis." + str(i) + ".log")

        markers = os.path.join(indir, "markers.summary.table.txt.gz")

        universe = os.path.join(
            indir, "markers.cluster." + str(i) + ".universe.txt.gz")

        if not os.path.exists(universe):
            E.warn("Skipping geneset analysis: %s does not exist" % universe)
            continue

        statements.append('''Rscript %(tenx_dir)s/R/genesetAnalysis.R
                            --markers=%(markers)s
                            --universe=%(universe)s
                            --species=%(species)s
                            --annotation=%(anno)s
                            --kegg_pathways=%(kegg_pathways)s
                            --gmt_names=%(gmt_names)s
                            --gmt_files=%(gmt_files)s
                            --cluster=%(i)s
                            --adjpthreshold=0.1
                            --direction=positive
                            --outdir=%(outdir)s
                            &> %(logfile)s
                      ''' % locals())

    P.run(statements)

    IOTools.touch_file(outfile)


@transform(genesetAnalysis,
           regex(r"(.*)/.*.sentinel"),
           r"\1/geneset.analysis.xlsx")
def summariseGenesetAnalysis(infile, outfile):
    '''
    Summarise the geneset over-enrichment analyses of cluster marker genes.

    Enriched pathways are summarised in an Excel table and a heatmap.
    '''

    outdir = os.path.dirname(outfile)

    # need to sort out the dependencies properly!
    genesetdir = os.path.dirname(infile)

    gmt_names, gmt_files = parseGMTs()

    with open(os.path.join(Path(outdir).parents[0],
                           "cluster.dir",
                           "nclusters.txt"), "r") as nclust:
        nclusters = nclust.readline().strip()

    job_memory = "20G"

    logfile = outfile + ".log"

    use_adjusted = str(PARAMS["genesets_use_adjusted_pvalues"]).upper()
    show_common = str(PARAMS["genesets_show_common"]).upper()

    statement = '''Rscript %(tenx_dir)s/R/summariseGenesets.R
                         --genesetdir=%(genesetdir)s
                         --gmt_names=%(gmt_names)s
                         --nclusters=%(nclusters)s
                         --mingenes=2
                         --pvaluethreshold=%(genesets_pvalue_threshold)s
                         --padjustmethod=%(genesets_padjust_method)s
                         --useadjusted=%(use_adjusted)s
                         --minoddsratio=%(genesets_min_odds_ratio)s
                         --showcommon=%(show_common)s
                         --outfile=%(outfile)s
                         --prefix=genesets
                         --plotdirvar=clusterGenesetsDir
                    &> %(logfile)s
                      '''

    P.run(statement)


# ------------------- < within cluster geneset analysis > ------------------- #

@active_if(PARAMS["findmarkers_between"])
@follows(summariseMarkersBetweenConditions)
@transform(findMarkersBetweenConditions,
           regex(r"(.*)/condition.markers.dir/.*.sentinel"),
           add_inputs(getGenesetAnnotations),
           r"\1/condition.genesets.dir/genesetAnalysisBetweenConditions.sentinel")
def genesetAnalysisBetweenConditions(infiles, outfile):
    '''
    Naive geneset over-enrichment analysis of genes DE within-cluster.

    Testing is performed with the gsfisher package.

    GO categories and KEGG pathways are tested by default.

    Arbitrary sets of genes cat be supplied as GMT files
    (e.g. such as those from MSigDB).
    '''

    findMarkersLog, genesetAnno = infiles

    indir = os.path.dirname(findMarkersLog)

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.mkdir(outdir)

    anno = os.path.join(os.path.dirname(genesetAnno),
                        "ensembl.to.entrez.txt.gz")

    kegg_pathways = os.path.join(os.path.dirname(genesetAnno),
                                 "kegg_pathways.rds")

    genesets = [x for x in PARAMS.keys() if x.startswith("genesets_")]

    gmt_names, gmt_files = parseGMTs()



    with open(os.path.join(Path(outdir).parents[0],
                           "cluster.dir",
                           "nclusters.txt"), "r") as nclust:
        nclusters = nclust.readline().strip()


    job_memory = "20G"

    statements = []

    species = PARAMS["annotation_species"]
    tenx_dir = PARAMS["tenx_dir"]

    for i in range(0, int(nclusters)):

        logfile = os.path.join(
            outdir, "geneset.analysis.between." + str(i) + ".log")

        markers = os.path.join(
            indir, "markers.between." +
            PARAMS["findmarkers_between_testfactor"] +
            ".summary.table.txt.gz")

        universe = os.path.join(
            indir, "markers.between." +
            PARAMS["findmarkers_between_testfactor"] +
            ".cluster." + str(i) + ".universe.txt.gz")

        if not os.path.exists(universe):
            E.warn("Skipping geneset analysis: %s does not exist" % universe)
            continue

        statements.append('''Rscript %(tenx_dir)s/R/genesetAnalysis.R
                            --markers=%(markers)s
                            --universe=%(universe)s
                            --species=%(species)s
                            --annotation=%(anno)s
                            --kegg_pathways=%(kegg_pathways)s
                            --gmt_names=%(gmt_names)s
                            --gmt_files=%(gmt_files)s
                            --cluster=%(i)s
                            --adjpthreshold=0.1
                            --direction=both
                            --prefix=genesets.between
                            --outdir=%(outdir)s
                            &> %(logfile)s
                      ''' % locals())

    P.run(statements)

    IOTools.touch_file(outfile)


@active_if(PARAMS["findmarkers_between"])
@transform(genesetAnalysisBetweenConditions,
           regex(r"(.*)/.*.sentinel"),
           r"\1/geneset.analysis.between.xlsx")
def summariseGenesetAnalysisBetweenConditions(infile, outfile):
    '''
    Summarise the geneset over-enrichment analyses of genes DE within-cluster.

    Enriched pathways are summarised in an Excel table and a heatmap.
    '''

    outdir = os.path.dirname(outfile)

    genesetdir = os.path.dirname(infile)

    with open(os.path.join(Path(outdir).parents[0],
                           "cluster.dir",
                           "nclusters.txt"), "r") as nclust:
        nclusters = nclust.readline().strip()


    job_memory = "20G"

    logfile = outfile + ".log"

    genesets = [x for x in PARAMS.keys() if x.startswith("genesets_")]

    gmt_names, gmt_files = parseGMTs()

    use_adjusted = str(PARAMS["genesets_use_adjusted_pvalues"]).upper()
    show_common = str(PARAMS["genesets_show_common"]).upper()

    statement = '''Rscript %(tenx_dir)s/R/summariseGenesets.R
                         --genesetdir=%(genesetdir)s
                         --gmt_names=%(gmt_names)s
                         --nclusters=%(nclusters)s
                         --mingenes=2
                         --pvaluethreshold=%(genesets_pvalue_threshold)s
                         --padjustmethod=%(genesets_padjust_method)s
                         --useadjusted=%(use_adjusted)s
                         --showcommon=%(show_common)s
                         --outfile=%(outfile)s
                         --prefix=genesets.between
                         --plotdirvar=conditionGenesetsDir
                    &> %(logfile)s
                      '''

    P.run(statement)


# ---------------------- < geneset analysis target > ---------------------- #

@follows(summariseGenesetAnalysis,
         summariseGenesetAnalysisBetweenConditions)
def genesets():
    pass


# ########################################################################### #
# ##################### Target to collect plots ############################# #
# ########################################################################### #

@follows(clustree,
         plotTSNEPerplexities, plotTSNEFactors,
         plotTSNEGenes, plotTSNEMarkers,
         plotUMAPFactors, diffusionMap,
         plotGroupNumbers)
def plots():
    '''
    Intermediate target to collect plots.
    '''

    pass


# ########################################################################### #
# ################## PDF report generation (via Latex) ###################### #
# ########################################################################### #

# High quality pdf reports are generated which can be easily shared.
#
# The reports incorporate raster (png) graphics. PDF versions of each graphic
# are also avaliable in the individual run folders.

@follows(markers,
         genesets,
         plots)
@transform(summariseGenesetAnalysis,
           regex("(.*)/cluster.genesets.dir/geneset.analysis.xlsx"),
           r"\1/latex.dir/report.vars.sty")
def latexVars(infile, outfile):
    '''
    Prepare a file containing the latex variable definitions.
    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    runDir = Path(outdir).parents[0]

    outfile_name = os.path.basename(outfile)

    clusterDir = os.path.join(runDir,
                              "cluster.dir")

    clusterGenesetsDir = os.path.join(runDir,
                              "cluster.genesets.dir")

    clusterMarkerDEPlotsDir = os.path.join(runDir,
                              "cluster.marker.de.plots.dir")

    clusterMarkerTSNEPlotsDir = os.path.join(runDir,
                                             "cluster.marker.tsne.plots.dir")

    clusterMarkersDir = os.path.join(runDir,
                                     "cluster.markers.dir")

    conditionGenesetsDir = os.path.join(runDir,
                              "condition.genesets.dir")

    conditionMarkerDEPlotsDir = os.path.join(runDir,
                              "condition.marker.de.plots.dir")

    conditionMarkerTSNEPlotsDir = os.path.join(runDir,
                                             "condition.marker.tsne.plots.dir")

    conditionMarkersDir = os.path.join(runDir,
                                     "condition.markers.dir")

    genelistsDir = os.path.join(runDir,
                                "genelists.dir")

    diffmapDir = os.path.join(runDir,
                              "diffmap.dir")

    groupNumbersDir = os.path.join(runDir,
                                   "group.numbers.dir")

    tsneDir = os.path.join(runDir,
                           "tsne.dir")

    umapDir = os.path.join(runDir,
                           "umap.dir")


    # runDir is the directory containing the begin.rds object.
    sampleDir = Path(outdir).parents[1]

    runDirBaseName = os.path.basename(runDir)

    nPCs, resolution, algorithm, deTest = runDirBaseName.split("_")

    runName = runDirBaseName.replace("_", "\\_")

    runDetails = ("no. components: " + str(nPCs) +
                  ", cluster resolution: " + str(resolution) +
                  ", cluster algorithm: " + str(algorithm) +
                  ", de test: " + deTest)

    reductionType = PARAMS["dimreduction_method"]

    sample = Path(outfile).parts[0].split(".")[0]
    jobName = sample + "_" + runName.replace(".cluster.dir", "")

    sample = sample.replace("_", "\\_")

    latentvars = PARAMS["regress_latentvars"].replace("_", "\\_")

    if PARAMS["findmarkers_conserved"]:
        conservedFactor = PARAMS["findmarkers_conserved_factor"]
        conservedFactor = conservedFactor.replace("_", "\\_")
    else:
        conservedFactor = "None"

    if PARAMS["findmarkers_conserved_between"]:
        conservedBetweenFactor = PARAMS["findmarkers_conserved_between_factor"]
        conservedBetweenFactor = conservedBetweenFactor.replace("_", "\\_")
    else:
        conservedBetweenFactor = "None"

    vars = {"sample": "%(sample)s" % locals(),
            "projectName": "%(projectname)s" % PARAMS,
            "reportAuthor": "%(author)s" % PARAMS,
            "runDir": "%(runDir)s" % locals(),
            "sampleDir": "%(sampleDir)s" % locals(),
            "clusterDir": "%(clusterDir)s" % locals(),
            "tsneDir": "%(tsneDir)s" % locals(),
            "clusterGenesetsDir": "%(clusterGenesetsDir)s" % locals(),
            "clusterMarkerDEPlotsDir": "%(clusterMarkerDEPlotsDir)s" % locals(),
            "clusterMarkerTSNEPlotsDir": "%(clusterMarkerTSNEPlotsDir)s" % locals(),
            "clusterMarkersDir": "%(clusterMarkersDir)s" % locals(),
            "conditionGenesetsDir": "%(conditionGenesetsDir)s" % locals(),
            "conditionMarkerDEPlotsDir": "%(conditionMarkerDEPlotsDir)s" % locals(),
            "conditionMarkerTSNEPlotsDir": "%(conditionMarkerTSNEPlotsDir)s" % locals(),
            "conditionMarkersDir": "%(conditionMarkersDir)s" % locals(),
            "genelistsDir": "%(genelistsDir)s" % locals(),
            "diffmapDir": "%(diffmapDir)s" % locals(),
            "groupNumbersDir": "%(groupNumbersDir)s" % locals(),
            "umapDir": "%(umapDir)s" % locals(),
            "runName": "%(runName)s" % locals(),
            "runDetails": "%(runDetails)s" % locals(),
            "tenxDir": "%(tenx_dir)s" % PARAMS,
            "nPCs": "%(nPCs)s" % locals(),
            "reductionType": "%(reductionType)s" % locals(),
            "tSNEPerplexity": "%(tsne_perplexity)s" % PARAMS,
            "tSNEMaxIter": "%(tsne_maxiter)s" % PARAMS,
            "tSNEFast": "%(tsne_fast)s" % PARAMS,
            "nPositiveMarkers": "%(exprsreport_n_positive)s" % PARAMS,
            "nNegativeMarkers": "%(exprsreport_n_negative)s" % PARAMS,
            "resolution": "%(resolution)s" % locals(),
            "clusteringAlgorithm": "%(algorithm)s" % locals(),
            "deTest": "%(deTest)s" % locals(),
            "threshUse": "%(findmarkers_threshuse)s" % PARAMS,
            "minPct": "%(findmarkers_minpct)s" % PARAMS,
            "qcMinGenes": "%(qc_mingenes)s" % PARAMS,
            "qcMaxMito": "%(qc_maxpercentmito)s" % PARAMS,
            "minCells": "%(qc_mincells)s" % PARAMS,
            "modelType": "%(regress_modeluse)s" % PARAMS,
            "latentVariables": "%(latentvars)s" % locals(),
            "cellCycle": "%(regress_cellcycle)s" % PARAMS,
            "sdCutOff": "%(vargenes_sdcutoff)s" % PARAMS,
            "conservedFactor": "%(conservedFactor)s" % locals(),
            "conservedBetweenFactor": "%(conservedBetweenFactor)s" % locals()}

    with open(outfile, "w") as ofh:
        for command, value in vars.items():

            ofh.write("\\newcommand{\\" + command + "}{" + value + "}\n")


@transform(latexVars,
           regex("(.*)/report.vars.sty"),
           r"\1/geneExpressionReport.pdf")
def geneExpressionReport(infile, outfile):
    '''
     Prepare a PDF report of the expression of genes interest.

     The expression of  manually specified sets of genes and of
     discovered cluster markers is visualised.
    '''

    outfile_name = os.path.basename(outfile)
    jobName = outfile_name[:-len(".pdf")]

    outdir = os.path.dirname(outfile)
    compilation_dir = os.path.join(outdir, ".latex_compilation.dir")

    latexVars = os.path.join(outdir, "report.vars")

    try:
        os.stat(compilation_dir)
    except FileNotFoundError:
        os.mkdir(compilation_dir)

    statement = '''pdflatex -output-directory=%(compilation_dir)s
                            -jobname=%(jobName)s
      '\\def\\latexVars{%(latexVars)s}
       \\def\\reportTitle{pipeline\\_seurat.py: gene expression report}
       \\input %(tenx_dir)s/pipelines/pipeline_seurat/geneExpressionReport.tex
       \\input %(tenx_dir)s/latex/endmatter.tex'
       '''

    # Deliberately run twice - necessary for LaTeX compilation..
    P.run(statement)
    P.run(statement)

    # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, outfile_name),
                outfile)


@transform(latexVars,
           regex("(.*)/report.vars.sty"),
           r"\1/summaryReport.pdf")
def summaryReport(infile, outfile):
    '''
    Prepare a PDF summary report.
    '''

    outfile_name = os.path.basename(outfile)
    jobName = outfile_name[:-len(".pdf")]

    outdir = os.path.dirname(outfile)
    rundir = Path(outdir).parents[0]

    compilation_dir = os.path.join(outdir, ".latex_compilation.dir")

    latexVars = os.path.join(outdir, "report.vars.sty")

    try:
        os.stat(compilation_dir)
    except FileNotFoundError:
        os.mkdir(compilation_dir)

    statement = '''pdflatex -output-directory=%(compilation_dir)s
                            -jobname=%(jobName)s
      '\\input %(latexVars)s
       \\def\\reportTitle{pipeline\\_seurat.py: summary report}
                '''

    statement += '''
      \\input %(tenx_dir)s/pipelines/pipeline_seurat/introReport.tex
      '''

    if(os.path.exists("data.dir")):
        statement += '''
          \\input %(tenx_dir)s/pipelines/pipeline_seurat/beginReport.tex
          '''

    statement += '''
      \\input %(tenx_dir)s/pipelines/pipeline_seurat/clusterReport.tex
      '''

    # When relevant, add section that compares
    # two conditions within each cluster
    if os.path.exists(
            os.path.join(rundir, "condition.markers.dir", "findMarkersBetweenConditions.sentinel")):

        wcc_section_name = "withinClusterComparisonSection.tex"
        statement += '''
          \\input %(tenx_dir)s/pipelines/pipeline_seurat/%(wcc_section_name)s
          '''

    statement += '''\\input %(tenx_dir)s/latex/endmatter.tex'
    '''

    # Deliberately run twice - necessary for LaTeX compilation..
    P.run(statement)
    P.run(statement)

    # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, outfile_name),
                outfile)


@follows(mkdir("reports.dir"), geneExpressionReport)
@transform(summaryReport,
           regex(r"(.*).seurat.dir/(.*)/latex.dir/summaryReport.pdf"),
           r"reports.dir/\1.\2/export.sentinel")
def export(infile, outfile):
    '''
    Link output files to a directory in the "reports.dir" folder.

    Prepare folders containing the reports, differentially expressed genes
    and geneset tables for each analysis.
    '''


    sample = Path(infile).parts[0].split(".")[0]

    cluster_run = Path(infile).parts[1]

    out_dir = os.path.join("reports.dir",
                           ".".join([sample, cluster_run]))

    run_dir = Path(os.path.dirname(infile)).parents[0]

    try:
        os.stat(out_dir)
    except FileNotFoundError:
        os.mkdir(out_dir)

    between_xlsx = "markers.between." + \
                   str(PARAMS["findmarkers_between_testfactor"]) + \
                   ".summary.table.xlsx"

    targets = [os.path.join(run_dir,"latex.dir","geneExpressionReport.pdf"),
               os.path.join(run_dir,"latex.dir","summaryReport.pdf"),
               os.path.join(run_dir,"cluster.markers.dir","markers.summary.table.xlsx"),
               os.path.join(run_dir,"condition.markers.dir",between_xlsx),
               os.path.join(run_dir, "cluster.genesets.dir","geneset.analysis.xlsx"),
               os.path.join(run_dir, "condition.genesets.dir","geneset.analysis.between.xlsx")]

    for target_file in targets:


        if os.path.exists(target_file):

            target = os.path.basename(target_file)

            link_name = os.path.join(out_dir, target)

            os.symlink(os.path.relpath(target_file, start=out_dir),
                       link_name)

    IOTools.touch_file(outfile)


# --------------------------- < report target > ----------------------------- #

# This is the target normally used to execute the pipeline.

@follows(export)
def report():
    pass


# ########################################################################### #
# ######################### Auxillary functions ############################# #
# ########################################################################### #

@transform(cluster,
           regex(r"(.*)/cluster.sentinel"),
           r"\1/cluster_counts.rds")
def aggregateUMIsPseudobulks(infile, outfile):
    '''
    Aggregate UMI counts across cells within cluster to form pseudobulks.

    Useful for performing e.g. DESeq2 analysis of clusters from
    multiple samples.
    '''

    outdir = os.path.dirname(infile)
    cluster_ids = os.path.join(outdir, "cluster_ids.rds")

    seurat_dir = Path(outfile).parents[1]
    sample_data_dir = str(seurat_dir).replace(".seurat", "")
    run_dir = Path(seurat_dir).parents[0]

    tenxdir = os.path.join(run_dir, 'data.dir', sample_data_dir)

    log_file = os.path.join(outdir, 'aggregated_clusters.log')

    statement = '''Rscript %(tenx_dir)s/R/aggregate_umis_pseudobulks.R
                           --tenxdir=%(tenxdir)s
                           --clusterids=%(cluster_ids)s
                           --outfile=%(outfile)s
                           &> %(log_file)s
                        '''

    P.run(statement)


# ------------------------ < auxillary target > ----------------------------- #

@follows(aggregateUMIsPseudobulks)
def aux():
    pass


# ########################################################################### #
# ##################### full target: to run all tasks ####################### #
# ########################################################################### #

@follows(report)
def full():
    pass


# ------------------- < ***** end of pipeline **** > ------------------------ #

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))

##############################################################################
#
#   Kennedy Institute of Rheumatology
#
#   $Id$
#
#   Copyright (C) 2018 Stephen Sansom
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
###############################################################################

"""===========================
Pipeline Seurat
===========================

:Author: Sansom lab
:Release: $Id$
:Date: |today|
:Tags: Python

Overview
========

This pipeline wraps the Satija lab's Seurat (http://satijalab.org/seurat/)
package using a set of Rscripts.

For key parameters a range of choices can be specified. The pipeline will
generate one report for each parameter combination, dispatching analyses
from multiple samples in parallel for execution on a HPC cluster.

The pipeline also performs cluster geneset enrichment analysis using the
"gsfisher" R package (http://github/sansomlab/gsfisher).

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_seurat.py config


Input files
-----------

The pipeline can be run either:
(A) starting from a suitable count matrix and metadata file (such as
the output of pipeline_cellranger.py) or
(B) starting from a saved seurat object. This is useful for analysing
an object to which reduced dimensions from another method (e.g. zinbwave)
have been added.
Optionally, velocity plots can be included, which require the optional
run of the tool dropEst within the cellranger pipeline (see below).

(A) Starting from a processed tenx count matrix (and a metadata.tsv file).

Typically involves linking "dataset.dir" subfolders from a
pipeline_cellranger.py run.

A folder containing the expression matrix (market exchange format)
and metadata.tsv file should be linked into a "data.dir" subfolder.
The folder names must end with ".dir".

e.g.

$ ls data.dir
agg.dir               d1_control_mono.dir  d2_butyrate_mono.dir
d1_butyrate_mono.dir  d1_tmp195_mono.dir   d2_control_mono.dir

$ ls data.dir/agg.dir/
barcodes.tsv  genes.tsv  matrix.mtx  metadata.tsv

(B) Starting from a saved seurat object.

The pipeline can run downstream analysis on a saved seurat object (RDS
format) on which qc, data normalisation, selection of variable genes and
dimension reduction has been performed.

Each sample should be placed (or linked) as a "begin.rds" file in a directory
ending with ".seurat.dir", e.g.

wildtype.seurat.dir/begin.rds
knockout.seurat.dir/begin.rds
aggregated.seurat.dir/begin.rds

The supplied object must contain an RNA assay with populated "data" and "scale.data" slots for all genes (i.e. you need to run NormlizeData and ScaleData on the RNA assay).

The seurat "JackStraw" and "ScoreJackStraw" functions must have run on the reduced dimensions (e.g. pca) of the default assay of the saved object.

The default assay of the saved object will be used for cell-level analyses such as cluster discovery, computation of tSNE/umap coordinates and pseudotime. Hence, if, for example, integration has been performed, "integrated" should be set as the default assay. For gene level analyses the pipeline will always use the RNA assay regardless of the default assay.

(Optional - velocity) Starting from aggregated dropEst output matrix.

Typically involves linking "dropEst-datasets.dir/sample.layers" subfolders from the
pipeline_cellranger.py run.

Similar to (A), a "data.velocity.dir" folder has to be created with
subfolders of the different conditions. The folder names must end
with ".dir" and folder structure should correspond to (A).


Dependencies
------------

This pipeline requires:

* cgat-core: https://github.com/cgat-developers/cgat-core
* cellranger: https://support.10xgenomics.com/single-cell-gene-expression/
* picard tools (optional): https://broadinstitute.github.io/picard/
* R & various packages.
* Latex.


Pipeline output
===============

For each sample and each combination of paramters the following is generated
in the "report.dir" subfoler:

* A pdf summary report
* A pdf gene expression report (arbitrary sets of genes can be specified)
* An excel table of cluster marker genes
* An excel table of cluster-enriched genesets
* Optionally an excel table of genes differentially expressed within cluster
* Optionally an excel table of genesets enriched in amongst genes
differentially expressed within-cluster

Intermediate results files are also retained in the per-sample directories.

"""

from ruffus import *
from pathlib import Path
import sys
import os
import re
import shutil
import glob
import sqlite3
import numpy as np
import pandas as pd
from scipy.stats.mstats import gmean
import cgatcore.experiment as E
from cgatcore import pipeline as P
import cgatcore.iotools as IOTools

# -------------------------- < parse parameters > --------------------------- #

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline.yml" % os.path.splitext(__file__)[0],
     "../pipeline.yml",
     "pipeline.yml"])

# set the location of the tenx code directory
if "tenx_dir" not in PARAMS.keys():
    PARAMS["tenx_dir"] = Path(__file__).parents[1]
else:
    raise ValueError("Could not set the location of the tenx code directory")


# ----------------------- < pipeline configuration > ------------------------ #

# handle pipeline configuration
if len(sys.argv) > 1:
        if(sys.argv[1] == "config") and __name__ == "__main__":
                    sys.exit(P.main(sys.argv))


# ########################################################################### #
# ############ construct one seurat object per input matrix ################# #
# ########################################################################### #

# QC, normalisation and dimension reduction are performed on the object.

@transform("data.dir/*.dir",
           regex(r".*/(.*).dir"),
           r"\1.seurat.dir/begin.rds")
def beginSeurat(infile, outfile):
    '''Setup the Seurat object and save it in RDS format.

       The Rscript "seurat_begin.R" reads in the raw data, performs
       QC filtering, removal of unwanted varation, identification of
       variable genes and PCA-based dimension reduction.
    '''

    outdir = outfile.split("/")[0]

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    sample_name = infile.split("/")[-1].split(".")[0]

    job_memory = PARAMS["resources_memory_standard"]
    job_threads = PARAMS["resources_numcores"]

    log_file = outfile.replace(".rds", ".log")
    metadata = os.path.join(infile, "metadata.tsv.gz")

    if PARAMS["subsetcells_active"]:

        cells_to_use = PARAMS["subsetcells_" + sample_name]

        if PARAMS["subsetcells_type"] == "barcode_list":

            if not os.path.exists(cells_to_use) or cells_to_use == "use.all":
                raise ValueError("Invalid cell subsetting parameter"
                                 " specification")

            subset = '''--subsetcells=%(cells_to_use)s
                     ''' % locals()

        elif PARAMS["subsetcells_type"] == "factor":

            subset_factor = PARAMS["subsetcells_factor"]

            subset = '''--subsetfactor=%(subset_factor)s
                        --subsetlevel=%(cells_to_use)s
                     ''' % locals()

        else:
            raise ValueError("Unknown type of subsetting requested")

    else:
        subset = ""


    # Deal with blacklist
    if PARAMS["blacklist_active"]:
        blacklist = '''--blacklist=%(blacklist_path)s
                    ''' % PARAMS
    else:
        blacklist = ""


    # Deal with cell-cycle options
    if ( os.path.isfile(PARAMS["cellcycle_sgenes"]) and
         os.path.isfile(PARAMS["cellcycle_g2mgenes"]) ):

        cell_cycle_genes = '''--sgenes=%(cellcycle_sgenes)s
                              --g2mgenes=%(cellcycle_g2mgenes)s
                           ''' % PARAMS

    else:
        cell_cycle_genes = ""


    if PARAMS["regress_cellcycle"] != "none":
        cell_cycle_regress = '''--cellcycle=%(regress_cellcycle)s
                             ''' % PARAMS
    else:
        cell_cycle_regress = ""

    if PARAMS["qc_seed"] != "none":
        seed = '''--seed=%(qc_seed)s''' % PARAMS
    else:
        seed = ""

    # Turn Python boolean into R logical
    downsamplecells = str(PARAMS["qc_downsamplecells"]).upper()

    # Deal with maxcount option
    if PARAMS["qc_maxcount"] != "none":
        maxcount = '''--qcmaxcount=%(qc_maxcount)s''' % PARAMS
    else:
        maxcount = ""

    statement = '''Rscript %(tenx_dir)s/R/seurat_begin.R
                   --tenxdir=%(infile)s
                   --project=%(sample_name)s
                   --outdir=%(outdir)s
                   --groupby=%(qc_groupby)s
                   --mingenes=%(qc_initial_mingenes)s
                   --mincells=%(qc_mincells)s
                   --qcmingenes=%(qc_mingenes)s
                   --qcminpercentmito=%(qc_minpercentmito)s
                   --qcmaxpercentmito=%(qc_maxpercentmito)s
                   --metadata=%(metadata)s
                   --downsamplecells=%(downsamplecells)s
                   --normalizationmethod=%(normalization_method)s
                   --latentvars=%(regress_latentvars)s
                   --modeluse=%(regress_modeluse)s
                   --vargenesmethod=%(vargenes_method)s
                   --topgenes=%(vargenes_topgenes)s
                   --sdcutoff=%(vargenes_sdcutoff)s
                   --xlowcutoff=%(vargenes_xlowcutoff)s
                   --xhighcutoff=%(vargenes_xhighcutoff)s
                   --minmean=%(vargenes_minmean)s
                   --vargenespadjust=%(vargenes_padjust)s
                   --jackstrawnumreplicates=%(dimreduction_jackstraw_n_replicate)s
                   --numcores=12
                   --plotdirvar=sampleDir
                   %(subset)s
                   %(blacklist)s
                   %(seed)s
                   %(cell_cycle_genes)s
                   %(cell_cycle_regress)s
                   %(maxcount)s
                   &> %(log_file)s
                '''

    P.run(statement)

# ########################################################################### #
# ############ Begin per-parameter combination analysis runs ################ #
# ########################################################################### #

# For each sample, one run will be performed for each combination
# of the following key parameter choices (as defined in the "runspecs"):
#
# * cluster resolution
# * cluster algorithm
# * number of PCA components
# * differential expression algorithm

def genClusterJobs():
    '''
    Generate cluster jobs with all paramter combinations.
    '''

    resolutions_str = str(PARAMS["runspecs_cluster_resolutions"])
    resolutions = resolutions_str.strip().replace(" ", "").split(",")

    algos_str = str(PARAMS["runspecs_cluster_algorithms"])
    algos = algos_str.strip().replace(" ", "").split(",")

    tests = str(
        PARAMS["runspecs_de_tests"]).strip().replace(" ", "").split(",")

    if PARAMS["runspecs_skip"] is not None:
        skip = PARAMS["seurat_skip"].strip().replace(" ", "").split(",")
    else:
        skip = []

    pcs_str = str(PARAMS["runspecs_n_components"])
    pcs = pcs_str.strip().replace(" ", "").split(",")


    samples = glob.glob("*.seurat.dir")

    subdir = "cluster.dir"
    outname = "cluster.sentinel"

    for sample in samples:

        infile = os.path.join(sample, "begin.rds")

        for test in tests:

            for pca in pcs:

                for algorithm in algos:

                    if PARAMS["runspecs_predefined_clusters"] :
                        outdir = "_".join([pca, "predefined", algorithm, test])
                        if(os.path.join(sample, outdir) in skip):
                            continue
                        outfile = os.path.join(sample, outdir, subdir, outname)
                        yield [infile, outfile]


                    for resolution in resolutions:

                            outdir = "_".join([pca, resolution, algorithm, test])
                            if(os.path.join(sample, outdir) in skip):
                                continue
                            outfile = os.path.join(sample, outdir, subdir, outname)
                            yield [infile, outfile]


@follows(beginSeurat)
@files(genClusterJobs)
def cluster(infile, outfile):
    '''Perform clustering on a saved seurat object.

       The single-cells are clustered using the given number of PCA components,
       resolution and alogorithm.

       Clusters are written to "cluster_ids.txt".
    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.makedirs(outdir)

    outname = os.path.basename(outfile)
    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    sample = outdir.split(".seurat.dir/")[0]

    reductiontype = PARAMS["dimreduction_method"]

    if(components=="sig"):
        comp="--usesigcomponents=TRUE"
    else:
        comp="--components=%(components)s" % locals()

    job_memory = PARAMS["resources_memory_standard"]

    log_file = outfile.replace(".sentinel", ".log")

    if resolution == "predefined":

        cluster_file = sample + ".cluster_ids.rds"

        if os.path.exists(cluster_file):
            predefined = "--predefined=%(cluster_file)s" % locals()

        else:
            raise ValueError("Predefined cluster assignment file (%(cluster_file)s) not found" % locals())

    else:
        predefined = ""

    cluster_nneighbours = PARAMS["cluster_nneighbors"]

    statement = '''Rscript %(tenx_dir)s/R/seurat_cluster.R
                   --seuratobject=%(infile)s
                   %(comp)s
                   %(predefined)s
                   --nneighbors=%(cluster_nneighbors)s
                   --resolution=%(resolution)s
                   --algorithm=%(algorithm)s
                   --outdir=%(outdir)s
                   --reductiontype=%(reductiontype)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


# ########################################################################### #
# ############### compare the clusters across resolutions ################### #
# ########################################################################### #


@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/cluster.dir/clustree.sentinel")
def clustree(infile, outfile):
    '''

    '''

    indir = os.path.dirname(infile)
    outdir = os.path.dirname(outfile)

    resolutions_str = str(PARAMS["runspecs_cluster_resolutions"])
    resolutions = resolutions_str.strip().replace(" ", "").split(",")

    cluster_ids = os.path.join(indir, "cluster_ids.rds")

    sampleDir = Path(cluster_ids).parts[0]
    runDir = Path(cluster_ids).parts[1]

    pcs, res, algo, de = runDir.split("_")

    id_files = [ os.path.join(sampleDir,
                              "_".join([pcs,r,algo,de]),
                              "cluster.dir",
                              "cluster_ids.rds")
                 for r in resolutions ]

    res_str = ",".join(resolutions)
    id_files_str = ",".join(id_files)

    print(id_files)

    log_file = outfile.replace("sentinel","log")

    job_memory=PARAMS["resources_memory_low"]

    statement = '''Rscript %(tenx_dir)s/R/seurat_clustree.R
                   --resolutions=%(res_str)s
                   --clusteridfiles=%(id_files_str)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)

# ################################ #
# ############# Paga ############# #
# ################################ #

@active_if(PARAMS["paga_run"])
@follows(beginSeurat)
@transform("*.seurat.dir/begin.rds",
           regex(r"(.*)/begin.rds"),
           r"\1/paga_input.sentinel")
def pagaPrepareInput(infile, outfile):
    '''
    '''
    seurat_obj = infile
    outdir = os.path.dirname(outfile)
    log_file = outfile.replace("sentinel","log")
    reductiontype = PARAMS["dimreduction_method"]

    if bool(re.search("sig", str(PARAMS["runspecs_n_components"]))) :
        comp="--usesigcomponents=TRUE"
    else :
        comp="--usesigcomponents=FALSE"

    statement = '''Rscript %(tenx_dir)s/R/paga_prepare_input.R
                   --seuratobject=%(seurat_obj)s
                   --reductiontype=%(reductiontype)s
                   --outdir=%(outdir)s
                   %(comp)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


@active_if(PARAMS["paga_run"])
@follows(pagaPrepareInput)
@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/paga.dir/paga.sentinel")
def paga(infile, outfile):
    '''

    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    cluster_assignments = os.path.join(Path(outdir).parents[0],
                                           "cluster.dir",
                                           "cluster_assignments.txt.gz")

    cluster_colors = os.path.join(Path(outdir).parents[0],
                                  "cluster.dir",
                                  "cluster_colors.txt")

    seurat_dir = Path(outdir).parents[1]
    reduced_dims_matrix_file = os.path.join(seurat_dir, "reduced_dims.tsv.gz")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    if components == "sig":
        sigcomps = os.path.join(seurat_dir, "sig_comps.txt")
        comps = pd.read_table(sigcomps, header=None)
        comps = comps[comps.columns[0]].tolist()
        comps = ','.join([ str(item) for item in comps])
    else :
        comps = list(range (1, int(components)+1))
        comps = ','.join([ str(item) for item in comps])

    job_memory = PARAMS["resources_memory_standard"]

    log_file = outfile.replace("sentinel","log")

    tenx_dir = PARAMS["tenx_dir"]

    k = PARAMS["paga_k"]

    statement = '''python %(tenx_dir)s/python/run_paga.py
                   --reduced_dims_matrix_file=%(reduced_dims_matrix_file)s
                   --outdir=%(outdir)s
                   --cluster_assignments=%(cluster_assignments)s
                   --cluster_colors=%(cluster_colors)s
                   --comps=%(comps)s
                   --k=%(k)s
                   &> %(log_file)s
                '''

    P.run(statement)
    IOTools.touch_file(outfile)

# ########################################################################### #
# ############### tSNE analysis and related plots ########################### #
# ########################################################################### #

@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/tsne.dir/tsne.sentinel")
def tSNE(infile, outfile):
    '''
    Run the tSNE analysis on a saved seurat object.

    A range of different perplexity choices can be specified.
    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    seurat_dir = Path(outdir).parents[1]
    seurat_object = os.path.join(seurat_dir, "begin.rds")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    reductiontype = PARAMS["dimreduction_method"]

    job_memory = PARAMS["resources_memory_standard"]

    perplexity_values = set(
        PARAMS["tsne_perplexities"].strip().replace(" ", "").split(",") +
        [PARAMS["tsne_perplexity"]])

    statements = []

    tenx_dir = PARAMS["tenx_dir"]
    tsne_fast = PARAMS["tsne_fast"]
    max_iter = PARAMS["tsne_maxiter"]

    if(components=="sig"):
        comp="--usesigcomponents=TRUE"
    else:
        comp="--components=%(components)s" % locals()

    for p in perplexity_values:

        outname = outfile.replace(".sentinel", "." + str(p) + ".txt")
        logfile = outname.replace(".txt", ".log")

        statements.append('''Rscript %(tenx_dir)s/R/seurat_tsne.R
                             --seuratobject=%(seurat_object)s
                             --clusterids=%(cluster_ids)s
                             %(comp)s
                             --reductiontype=%(reductiontype)s
                             --perplexity=%(p)s
                             --maxiter=%(max_iter)s
                             --fast=%(tsne_fast)s
                             --outfile=%(outname)s
                             &> %(logfile)s
                          ''' % locals())
    P.run(statements)
    IOTools.touch_file(outfile)

@transform(tSNE,
           regex(r"(.*)/tsne.sentinel"),
           r"\1/plot.tsne.perplexities.sentinel")
def plotTSNEPerplexities(infile, outfile):
    '''
    Visualise effect of the perplexity hyperparameter on tSNE layout.

    A page containing side-by-side plots of the different perplexity
    choices is produced.
    '''

    # concatenate all the tSNE results into a single table
    outdir = os.path.dirname(outfile)
    perplexities = PARAMS["tsne_perplexities"]
    perplexity_values = perplexities.strip().replace(" ", "").split(",")

    frames = []

    for p in perplexity_values:

        tsne_table = infile.replace("sentinel", str(p) + ".txt")

        # Perplexity values that are too high are silently skipped
        # in the previous task.
        if os.path.exists(tsne_table):

            data = pd.read_csv(tsne_table, sep="\t")
            data["perplexity"] = p
            frames.append(data)

    long = pd.concat(frames)

    long_table = infile.replace(".sentinel", ".perplexity.txt")
    long.to_csv(long_table, sep="\t", header=True, index=False)

    log_file = outfile.replace(".sentinel", ".log")

    job_memory = PARAMS["resources_memory_low"]

    statement = '''Rscript %(tenx_dir)s/R/plot_tsne_hyperparameters.R
                   --table=%(long_table)s
                   --shapefactor=%(plot_shape)s
                   --colorfactor=cluster
                   --hyperparameter=perplexity
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --plotdirvar=tsneDir
                   --outdir=%(outdir)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


# ########################################################################### #
# ############### UMAP analysis and related plots ########################### #
# ########################################################################### #

@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/umap.dir/umap.sentinel")
def UMAP(infile, outfile):
    '''
    Run the UMAP analysis on a saved seurat object.
    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    cluster_ids = infile.replace(".sentinel","_ids.rds")

    seurat_dir = Path(outdir).parents[1]
    seurat_object = os.path.join(seurat_dir, "begin.rds")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    reductiontype = PARAMS["dimreduction_method"]

    if(components=="sig"):
        comp="--usesigcomponents=TRUE"
    else:
        comp="--components=%(components)s" % locals()

    job_memory = PARAMS["resources_memory_standard"]

    tenx_dir = PARAMS["tenx_dir"]

    umap_method = PARAMS["umap_method"]
    umap_nneighbors = PARAMS["umap_nneighbors"]
    umap_mindist = PARAMS["umap_mindist"]
    umap_metric = PARAMS["umap_metric"]
    umap_nepochs = PARAMS["umap_nepochs"]
    umap_seed = PARAMS["umap_seed"]

    outname = outfile.replace(".sentinel", ".txt")
    logfile = outname.replace(".txt", ".log")

    statement = '''Rscript %(tenx_dir)s/R/seurat_umap.R
                             --seuratobject=%(seurat_object)s
                             --clusterids=%(cluster_ids)s
                             %(comp)s
                             --reductiontype=%(reductiontype)s
                             --method=%(umap_method)s
                             --nneighbors=%(umap_nneighbors)s
                             --mindist=%(umap_mindist)s
                             --metric=%(umap_metric)s
                             --nepochs=%(umap_nepochs)s
                             --seed=%(umap_seed)s
                             --outfile=%(outname)s
                             &> %(logfile)s
                          ''' % locals()

    P.run(statement)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ############################## Diffusion maps ############################# #
# ########################################################################### #

@active_if(PARAMS["diffusionmap_run"])
@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/diffusionmap.dir/dm.sentinel")
def diffusionMap(infile, outfile):
    '''
    Run the diffusion map analysis on a saved seurat object.
    '''

    outdir = os.path.dirname(outfile)
    cluster_ids = infile.replace(".sentinel","_ids.rds")

    seurat_dir = Path(outdir).parents[1]
    seurat_object = os.path.join(seurat_dir, "begin.rds")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    reductiontype = PARAMS["dimreduction_method"]
    if(components=="sig"):
        comp="--usesigcomponents=TRUE"
    else:
        comp="--components=%(components)s" % locals()

    if PARAMS["diffusionmap_usegenes"]:
        usegenes="--usegenes=TRUE"
    else:
        usegenes="--usegenes=FALSE"

    job_memory = PARAMS["resources_memory_high"]

    tenx_dir = PARAMS["tenx_dir"]

    diffmap_maxdim = PARAMS["diffusionmap_maxdim"]

    outname = outfile.replace(".sentinel", ".txt.gz")
    logfile = outname.replace(".txt", ".log")

    statement = '''Rscript %(tenx_dir)s/R/seurat_dm.R
                             --seuratobject=%(seurat_object)s
                             --clusterids=%(cluster_ids)s
                             %(usegenes)s
                             %(comp)s
                             --reductiontype=%(reductiontype)s
                             --maxdim=%(diffmap_maxdim)s
                             --outfile=%(outname)s
                             --outdir=%(outdir)s
                             --plotdirvar=diffmapDir
                             &> %(logfile)s
                          ''' % locals()

    P.run(statement)
    IOTools.touch_file(outfile)


# ########################################################################### #
# ####################### Known gene violin plots ########################### #
# ########################################################################### #


@active_if(PARAMS["knownmarkers_run"])
@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/known.markers.dir/known.markers.sentinel")
def knownMarkerViolins(infile, outfile):
    '''
       Make per-cluster violin plots from a given set of known marker genes.
    '''

    indir = os.path.dirname(infile)
    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.makedirs(outdir)

    cluster_ids = os.path.join(indir, "cluster_ids.rds")

    seurat_dir = Path(outdir).parents[1]
    seurat_object = os.path.join(seurat_dir, "begin.rds")


    if not os.path.exists(PARAMS["knownmarkers_file"]):
        raise ValueError("The specified known markers file does not exist")

    outprefix = outfile.replace(".sentinel", "")

    log_file = outfile.replace(".sentinel", ".log")

    job_memory = PARAMS["resources_memory_low"]

    statement = '''Rscript %(tenx_dir)s/R/plot_violins.R
                       --genetable=%(knownmarkers_file)s
                       --seuratobject=%(seurat_object)s
                       --seuratassay=RNA
                       --clusterids=%(cluster_ids)s
                       --outprefix=%(outprefix)s
                       --plotdirvar=knownmarkersDir
                       &> %(log_file)s
        '''

    P.run(statement)

    IOTools.touch_file(outfile)




# ########################################################################### #
# ################## Set the DR visualisation method ######################## #
# ########################################################################### #

# Used to show clusters, factors of interest and gene expression levels
# in various downstream functions

if PARAMS["dimreduction_visualisation"].lower() == "tsne":
    RDIMS_VIS_TASK = tSNE
    RDIMS_VIS_METHOD = "tsne"
    RDIMS_VIS_COMP_1 = "tSNE_1"
    RDIMS_VIS_COMP_2 = "tSNE_2"

elif PARAMS["dimreduction_visualisation"].lower() == "umap":
    RDIMS_VIS_TASK = UMAP
    RDIMS_VIS_METHOD = "umap"
    RDIMS_VIS_COMP_1 = "UMAP_1"
    RDIMS_VIS_COMP_2 = "UMAP_2"

else:
    raise ValueError('dimreduction_visualisation must be either "tsne" or "umap"')

# ########################################################################### #
# ########################### RNA Velocity ################################## #
# ########################################################################### #

# @active_if(PARAMS["velocity_run"])
# @transform(RDIMS_VIS_TASK,
#            regex(r"(.*)/(.*).dir/(.*).sentinel"),
#            r"\1/velocity.dir/plot.velocity.sentinel")
# def velocity(infile, outfile):
#     '''
#        Plot the RNA velocity.
#        This analysis is highly parameterised and different configurations can
#        suggest different interpretations of the data: it is strong recommended
#        to determine the best settings manually!
#     '''

#     outdir = os.path.dirname(outfile)
#     if not os.path.exists(outdir):
#         os.makedirs(outdir)

#     if RDIMS_VIS_METHOD == "tsne":
#         rdims_table = infile.replace(
#             "sentinel", str(PARAMS["tsne_perplexity"]) + ".txt")
#     elif RDIMS_VIS_METHOD == "umap":
#         rdims_table = infile.replace(
#             ".sentinel", ".txt")

#     sample = infile.split(".seurat.dir")[0]

#     matrixdir = os.path.join("data.velocity.dir",
#                              sample + ".dir")

#     log_file = outfile.replace(".sentinel", ".log")

#     job_threads = PARAMS["velocity_ncores"]
#     job_memory = PARAMS["resources_memory_low"]

#     rdims_vis_method = RDIMS_VIS_METHOD
#     rdim1 = RDIMS_VIS_COMP_1
#     rdim2 = RDIMS_VIS_COMP_2

#     statement = '''Rscript %(tenx_dir)s/R/plot_velocity.R
#                 --ncores=%(velocity_ncores)s
#                 --rdimstable=%(rdims_table)s
#                 --rdim1=%(rdim1)s
#                 --rdim2=%(rdim2)s
#                 --matrixdir=%(matrixdir)s
#                 --minmaxclustavemat=%(velocity_minmaxclustavemat)s
#                 --minmaxclustavnmat=%(velocity_minmaxclustavnmat)s
#                 --deltat=%(velocity_deltat)s
#                 --kcells=%(velocity_kcells)s
#                 --fitquantile=%(velocity_fitquantile)s
#                 --neighbourhoodsize=%(velocity_neighbourhoodsize)s
#                 --velocityscale=%(velocity_velocityscale)s
#                 --arrowscale=%(velocity_arrowscale)s
#                 --arrowlwd=%(velocity_arrowlwd)s
#                 --gridflow=%(velocity_gridflow)s
#                 --mingridcellmass=%(velocity_mingridcellmass)s
#                 --gridn=%(velocity_gridn)s
#                 --cellalpha=%(velocity_cellalpha)s
#                 --cellborderalpha=%(velocity_cellborderalpha)s
#                 --showaxes=%(velocity_showaxes)s
#                 --plotdirvar=velocityDir
#                 --plotcex=%(velocity_plotcex)s
#                 --outdir=%(outdir)s
#                 &> %(log_file)s
#                 '''

#     P.run(statement)
#     IOTools.touch_file(outfile)

@active_if(PARAMS["velocity_run"])
@follows(paga)
@transform(RDIMS_VIS_TASK,
           regex(r"(.*)/(.*).dir/(.*).sentinel"),
           r"\1/velocity.dir/scvelo.sentinel")
def scvelo(infile, outfile):
    '''
       Plot the RNA velocity.
       This analysis is highly parameterised and different configurations can
       suggest different interpretations of the data.
    '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    cluster_assignments = os.path.join(Path(outdir).parents[0],
                                           "cluster.dir",
                                           "cluster_assignemnts.txt.gz")

    cluster_colors = os.path.join(Path(outdir).parents[0],
                                  "cluster.dir",
                                  "cluster_colors.txt")

    if RDIMS_VIS_METHOD == "tsne":
        rdims_table = infile.replace(
            "sentinel", str(PARAMS["tsne_perplexity"]) + ".txt")
    elif RDIMS_VIS_METHOD == "umap":
        rdims_table = infile.replace(
            ".sentinel", ".txt")

    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    sample = infile.split(".seurat.dir")[0]
    layers_dir = os.path.join("data.velocity.dir",
                             sample + ".dir")

    if not os.path.exists(os.path.join(layers_dir,"exons.mtx.gz")):
        raise ValueError("dropest output not found. Please check that you "
                         "have symlinked the .layers directory")

    cluster_assignments = os.path.join(Path(outdir).parents[0],
                                           "cluster.dir",
                                           "cluster_assignments.txt.gz")

    job_memory = PARAMS["resources_memory_standard"]


    log_file = outfile.replace(".sentinel", ".log")
    tenx_dir = PARAMS["tenx_dir"]

    runs = { "default": { "method": rdims_vis_method,
                          "table": rdims_table,
                          "rdim1": rdim1, "rdim2": rdim2 }}

    if PARAMS["paga_run"]:

        pagafdg_table = os.path.join(Path(outdir).parents[0],
                                     "paga.dir",
                                     "paga_init_fa2.txt.gz")

        runs["pagafdg"] = {"method": "paga_fdg",
                           "table": pagafdg_table,
                           "rdim1": "FA1", "rdim2": "FA2"}

    statements = []

    for run, details in runs.items():

        r_method, r_tab, r_1, r_2 = details["method"], details["table"], \
                                    details["rdim1"], details["rdim2"]

        s = '''python %(tenx_dir)s/python/run_scvelo.py
                   --dropest_dir=%(layers_dir)s
                   --outdir=%(outdir)s
                   --cluster_assignments=%(cluster_assignments)s
                   --cluster_colors=%(cluster_colors)s
                   --rdim_method=%(r_method)s
                   --rdims=%(r_tab)s
                   --rdim1=%(r_1)s
                   --rdim2=%(r_2)s
                &> %(log_file)s
                ''' % locals()

        statements.append(s)

    P.run(statements)
    IOTools.touch_file(outfile)



# ########################################################################### #
# ###### Visualise gene expression across cells in reduced dimensions ####### #
# ########################################################################### #

@transform(RDIMS_VIS_TASK,
           regex(r"(.*)/(.*).dir/(.*).sentinel"),
           r"\1/rdims.visualisation.dir/plot.rdims.factor.sentinel")
def plotRdimsFactors(infile, outfile):
    '''
    Visualise the clusters on the chosen projection
    '''

    outdir = os.path.dirname(outfile)
    job_memory = PARAMS["resources_memory_standard"]

    if RDIMS_VIS_METHOD == "tsne":
        rdims_table = infile.replace(
            "sentinel", str(PARAMS["tsne_perplexity"]) + ".txt")
    elif RDIMS_VIS_METHOD == "umap":
        rdims_table = infile.replace(
            ".sentinel", ".txt")

    color_factors = ["cluster"]

    if PARAMS["plot_qcvars"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_qcvars"].split(",")]

    if PARAMS["plot_groups"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_groups"].split(",")]

    if PARAMS["plot_subgroup"] is not None:
        color_factors += [x.strip() for x in
                          PARAMS["plot_subgroup"].split(",")]

    # ensure list is unique whilst preserving order.
    color_factors = list(dict.fromkeys(color_factors))

    color_factors = "--colorfactors=" + ",".join(color_factors)


    if PARAMS["plot_shape"] is not None:
        shape_factors = "--shapefactor=%(plot_shape)s" % PARAMS
    else:
        shape_factors = ""

    log_file = outfile.replace(".sentinel", ".log")

    # bring vars into local scope..
    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    statement = '''Rscript %(tenx_dir)s/R/plot_rdims_factor.R
                   --method=%(rdims_vis_method)s
                   --table=%(rdims_table)s
                   --rdim1=%(rdim1)s
                   --rdim2=%(rdim2)s
                   %(shape_factors)s
                   %(color_factors)s
                   --pointsize=%(plot_pointsize)s
                   --pointalpha=%(plot_pointalpha)s
                   --outdir=%(outdir)s
                   --plotdirvar=rdimsVisDir
                   &> %(log_file)s
                '''

    P.run(statement)
    IOTools.touch_file(outfile)


@transform(RDIMS_VIS_TASK,
           regex(r"(.*)/(.*).dir/(.*).sentinel"),
           r"\1/genelists.dir/plot.rdims.genes.sentinel")
def plotRdimsGenes(infile, outfile):
    '''
    Visualise gene expression levels on reduced dimension coordinates

    The @data slot of the seurat object is used.
    '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.mkdir(outdir)

    sample_dir = str(Path(outdir).parents[1])
    seurat_object = os.path.join(sample_dir, "begin.rds")

    tex_path = os.path.join(outdir, "plot.rdims.known.genes.tex")

    rdims_vis_method = RDIMS_VIS_METHOD
    rdim1 = RDIMS_VIS_COMP_1
    rdim2 = RDIMS_VIS_COMP_2

    if PARAMS["exprsreport_genelists"]:
        genelists = glob.glob(
            os.path.join(PARAMS["exprsreport_genelist_dir"], "*.txt"))

        job_memory = PARAMS["resources_memory_standard"]

        if RDIMS_VIS_METHOD == "tsne":
            rdims_table = infile.replace(
                "sentinel", str(PARAMS["tsne_perplexity"]) + ".txt")
        elif RDIMS_VIS_METHOD == "umap":
            rdims_table = infile.replace(
                ".sentinel", ".txt")

        for genelist in genelists:

            fname = "plot.rdims.genes." + os.path.basename(genelist) + ".log"
            logfile = os.path.join(outdir, fname)

            if PARAMS["plot_shape"] is not None:
                shape = "--shapefactor=%(plot_shape)s" % PARAMS
            else:
                shape = ""

            statement = '''Rscript %(tenx_dir)s/R/plot_rdims_gene.R
                           --method=%(rdims_vis_method)s
                           --table=%(rdims_table)s
                           --seuratobject=%(seurat_object)s
                           --seuratassay=RNA
                           --rdim1=%(rdim1)s
                           --rdim2=%(rdim2)s
                           %(shape)s
                           --genetable=%(genelist)s
                           --pointsize=%(plot_pointsize)s
                           --pointalpha=%(plot_pointalpha)s
                           --outdir=%(outdir)s
                           --plotdirvar=genelistsDir
                           &> %(logfile)s
                       '''
            P.run(statement)

        # prepare a summary tex snippet for inclusion in the report.

        with(open(tex_path, "w")) as tex:

            for genelist in genelists:

                texf = os.path.join(
                    outdir,
                    "plot.rdims.genes." +
                    os.path.basename(genelist).replace(".txt", ""))

                gsname = os.path.basename(
                    genelist)[:-len(".txt")].replace("_", "\\_")

                tex.write(
                    "\\subsection{Expression of known genes: %s}\n" % gsname)
                tex.write(
                    "\\input{%(texf)s}\n" % locals())

            tex.write("\n")

    else:

        with(open(tex_path, "w")) as tex:

            tex.write("No genelists were specified.\n")
            tex.write("\n")

    IOTools.touch_file(outfile)


# ########################################################################### #
# ################# plot per-cluster summary statistics ##################### #
# ########################################################################### #

@transform(RDIMS_VIS_TASK,
           regex(r"(.*)/(.*).dir/(.*).sentinel"),
           r"\1/group.numbers.dir/plot.group.numbers.sentinel")
def plotGroupNumbers(infile, outfile):
    '''
    Plot statistics on cells by group, e.g. numbers of cells per cluster.
    '''

    outdir = os.path.dirname(outfile)

    sample_dir = str(Path(outdir).parents[1])
    seurat_object = os.path.join(sample_dir, "begin.rds")

    job_memory = PARAMS["resources_memory_standard"]

    if RDIMS_VIS_METHOD == "tsne":
        rdims_table = infile.replace(
            "sentinel", str(PARAMS["tsne_perplexity"]) + ".txt")
    elif RDIMS_VIS_METHOD == "umap":
        rdims_table = infile.replace(
            ".sentinel", ".txt")

    if PARAMS["plot_subgroup"] is not None:
        subgroupfactor = "--subgroupfactor=%(plot_subgroup)s" % PARAMS
    else:
        subgroupfactor = ""

    if PARAMS["plot_groups"] is not None:
        plot_groups = [x.strip() for x in
                       PARAMS["plot_groups"].split(",")]

        if "cluster" not in plot_groups:
            plot_groups.append("cluster")

        plot_groups = ",".join(plot_groups)

    else:
        plot_groups = "cluster"

    groupfactors = "--groupfactors={}".format(plot_groups)

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/plot_group_numbers.R
                   --table=%(rdims_table)s
                   --seuratobject=%(seurat_object)s
                   --seuratassay=RNA
                    %(groupfactors)s
                    %(subgroupfactor)s
                   --outdir=%(outdir)s
                   --plotdirvar=groupNumbersDir
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


# ########################################################################### #
# #################### Retrieve geneset annoations ########################## #
# ########################################################################### #

# Retrieve gene annotations and KEGG pathways.
#
# The "ensembl.to.entrez.txt.gz" table is needed for:
# - adding ensembl gene_ids to the findMarkers results table if s@misc$gene
#   is not set
# - translating ensembl gene_ids to entrez gene_ids for the geneset
#   analysis


@follows(mkdir("annotation.dir"))
@files(None, "annotation.dir/genesets.sentinel")
def getGenesetAnnotations(infile, outfile):
    '''Get mappings between Ensembl gene_ids and (i) Entrez ids
       and (ii) KEGG pathways.
    '''

    outdir = os.path.dirname(outfile)

    log_file = outfile.replace(".sentinel", ".log")

    job_memory = PARAMS["resources_memory_low"]

    if PARAMS["annotation_ensembl_host"] == "default":
        ensembl_host = ""
    else:
        ensembl_host = "--ensemblhost=%(annotation_ensembl_host)s" % PARAMS

    statement = '''Rscript %(tenx_dir)s/R/fetch_geneset_annotations.R
                 --ensemblversion=%(annotation_ensembl_release)s
                 %(ensembl_host)s
                 --species=%(annotation_species)s
                 --outdir=%(outdir)s
                 &> %(log_file)s
              '''

    P.run(statement)

    IOTools.touch_file(outfile)


# ########################################################################### #
# ############# Cluster marker identification and visualisation ############# #
# ########################################################################### #

@follows(getGenesetAnnotations)
@transform(cluster,
           regex(r"(.*)/cluster.dir/cluster.sentinel"),
           r"\1/cluster.markers.dir/findMarkers.sentinel")
def findMarkers(infile, outfile):
    '''
    Identification of cluster marker genes.

    This analysis is run in parallel for each cluster.
    '''

    indir = os.path.dirname(infile)
    outdir = os.path.dirname(outfile)

    cluster_ids = infile.replace(".sentinel","_ids.rds")

    clusters = pd.read_table(os.path.join(indir, "cluster_ids.txt"),
                            header=None)
    clusters = clusters[clusters.columns[0]].tolist()
    nclusters = len(clusters)

    seurat_object = os.path.join(Path(outdir).parents[1],
                                 "begin.rds")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    threshuse = PARAMS["findmarkers_threshuse"]
    minpct = PARAMS["findmarkers_minpct"]

    if PARAMS["findmarkers_conserved"]:
        conservedfactor = PARAMS["findmarkers_conserved_factor"]
        conservedpadj = PARAMS["findmarkers_conserved_padj"]
        conserved_options = '''--conservedfactor=%(conservedfactor)s
            --conservedpadj=%(conservedpadj)s
        '''
    else:
        conserved_options = ""

    job_memory = PARAMS["resources_memory_high"]

    tenx_dir = PARAMS["tenx_dir"]
    statements = []

    for i in range(min(clusters), max(clusters)+1):

        logfile = outfile.replace(".sentinel", "." + str(i) + ".log")
        statements.append('''Rscript %(tenx_dir)s/R/seurat_FindMarkers.R
                   --seuratobject=%(seurat_object)s
                   --seuratassay=RNA
                   --clusterids=%(cluster_ids)s
                   --cluster=%(i)s
                   --testuse=%(test)s
                   --minpct=%(minpct)s
                   --mindiffpct=-Inf
                   --threshuse=%(threshuse)s
                   %(conserved_options)s
                   --annotation=annotation.dir/ensembl.to.entrez.txt.gz
                   --outdir=%(outdir)s
                   &> %(logfile)s
                ''' % locals())

    P.run(statements)

    IOTools.touch_file(outfile)


@transform(findMarkers,
           regex(r"(.*)/findMarkers.sentinel"),
           r"\1/summariseMarkers.sentinel")
def summariseMarkers(infile, outfile):
    '''
    Make summary tables and plots of cluster marker genes.

    The per-cluster results files are aggregated. A heatmap of the top
    cluster markers is generated. A summary excel file is generated.
    Tables for geneset enrichment testing are prepared.
    '''

    outdir = os.path.dirname(outfile)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    seurat_object = os.path.join(Path(outdir).parents[1],
                               "begin.rds")

    if PARAMS["plot_subgroup"] is not None:
        subgroup = '''--subgroup=%(plot_subgroup)s''' % PARAMS
    else:
        subgroup = ""

    job_memory = PARAMS["resources_memory_high"]

    log_file = outfile.replace(".sentinel", ".log")


    # make sumamary tables and plots of the differentially expressed genes
    statement = '''Rscript %(tenx_dir)s/R/seurat_summariseMarkers.R
                   --seuratobject=%(seurat_object)s
                   --seuratassay=RNA
                   --clusterids=%(cluster_ids)s
                   %(subgroup)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


@transform(summariseMarkers,
           regex(r"(.*)/cluster.markers.dir/summariseMarkers.sentinel"),
           r"\1/cluster.marker.de.plots.dir/characteriseClusterMarkers.tex")
def characteriseClusterMarkers(infile, outfile):
    '''
    Characterise cluster marker genes.

    Diagnostic summary plots of differentially expressed genes
    and violin plots of cluster marker gene expression are generated.

    Parallelised per-cluster.
    '''

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.mkdir(outdir)

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.txt.gz")


    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    seurat_object = os.path.join(Path(outdir).parents[1],
                               "begin.rds")

    job_memory = PARAMS["resources_memory_low"]

    # not all clusters may have degenes
    degenes = pd.read_csv(marker_table, sep="\t")
    clusters = [x for x in set(degenes["cluster"].values)]

    tenx_dir = PARAMS["tenx_dir"]

    statements = []
    tex = []
    for i in clusters:

        log_file = outfile[:-len(".tex")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(tenx_dir)s/R/seurat_characteriseClusterDEGenes.R
                    --degenes=%(marker_table)s
                    --seuratobject=%(seurat_object)s
                    --seuratassay=RNA
                    --clusterids=%(cluster_ids)s
                    --cluster=%(i)s
                    --outdir=%(outdir)s
                    --useminfc=TRUE
                    --plotdirvar=clusterMarkerDEPlotsDir
                    &> %(log_file)s
                    ''' % locals()

        cluster_tex_file = ".".join(["characterise.degenes", str(i), "tex"])
        tex.append("\\input{\\clusterMarkerDEPlotsDir/" + cluster_tex_file + "}")
        statements.append(statement)

    P.run(statements)

    with open(outfile, "w") as out_tex:
        for line in tex:
            out_tex.write(line + "\n")


@transform(summariseMarkers,
           regex(r"(.*)/cluster.markers.dir/(.*).sentinel"),
           r"\1/cluster.marker.de.plots.dir/plotMarkerNumbers.sentinel")
def plotMarkerNumbers(infile, outfile):
    '''
    Summarise the numbers of per-cluster marker genes.
    '''

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.summary.table.txt.gz")

    outdir = os.path.dirname(outfile)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    job_memory = PARAMS["resources_memory_low"]

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/seurat_summariseMarkerNumbers.R
                   --degenes=%(marker_table)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   --minfc=2
                   --minpadj=0.05
                   --plotdirvar=clusterMarkerDEPlotsDir
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


@follows(summariseMarkers)
@transform(RDIMS_VIS_TASK,
           regex(r"(.*)/(.*).dir/(.*).sentinel"),
           r"\1/cluster.marker.rdims.plots.dir/plot.rdims.markers.sentinel")
def plotRdimsMarkers(infile, outfile):
    '''
    Visualise expression of discovered markers on rdims plots.

    An effort is made to prioritise the strongest cluster markers
    based on significance, expression frequency, expression level
    and fold change.
    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    seurat_object = os.path.join(Path(outdir).parents[1],
                                 "begin.rds")

    marker_summary_file = os.path.join(Path(outdir).parents[0],
                                       "cluster.markers.dir",
                                       "markers.summary.table.txt.gz")

    data = pd.read_csv(marker_summary_file, sep="\t")

    def _filterAndScore(data):
        # filter for strong cluster markers
        data = data[(data["p.adj"] < 0.01) &
                    (data["avg_logFC"].abs() > np.log(2)) &
                    (data["cluster_mean"] > 2) &
                    (data["pct.1"] > 0.25)]

        # compute a score based on all factors of interest.
        # here we use the product of the rank-normalised values
        # for fold change, expression level and adjusted p-value.
        # the aim is to give "better" markers higher scores.
        pscore = [1 - x for x in data["p.adj"].values]
        fscore = [np.exp(np.abs(x)) for x in data["avg_logFC"].values]
        escore = [np.log2(x) for x in data["cluster_mean"].values]

        # construct a matrix of the scores and take the geometric mean.
        temp = np.matrix([pscore,
                          fscore,
                          escore])

        data["score"] = np.squeeze(np.asarray(gmean(temp)))

        # keep only the best record for each gene
        data = data.sort_values(["score"], ascending=False)
        data = data.drop_duplicates(subset="gene_id", keep="first")

        # re-sort by cluster and then score
        data = data.sort_values(["cluster", "score"], ascending=[True, False])

        return data

    # define some helper functions..
    def _skimMarkers(data, n=40):
        # ensure we are ranked by cluster and score, best genes first.
        data = data.sort_values(["cluster", "score"], ascending=[True, False])

        # add the per cluster rankings
        data["grank"] = data.groupby(["cluster"]).cumcount()+1

        # de-duplicate keeping the marker for the cluster where
        # it has the best ranking.
        data = data.sort_values(["grank"], ascending=True)
        data = data.drop_duplicates(subset="gene_id", keep="first")

        # reorder and take the n best markers per cluster.
        data = data.sort_values(["cluster", "score"], ascending=[True, False])
        data = data.groupby("cluster").head(n)

        return data

    def _addGeneName(d):
        d["gene_name"] = d["gene"] + " (" + d["type"] + "; cluster " + \
                         d["cluster"].astype(str) + ")"
        return d

    def _report(d, name="none", seurat_object=seurat_object):

        # write the markers out to a table
        file_name = ".".join(["top", name, "cluster.markers.txt"])
        markers_file = os.path.join(outdir, file_name)
        d.to_csv(markers_file, header=True, sep="\t")

        job_memory = PARAMS["resources_memory_standard"]

        log_name = ".".join(["plot.rdims.top", name, "cluster.markers.log"])
        log_file = os.path.join(outdir, log_name)
        rdims_vis_method = RDIMS_VIS_METHOD
        rdim1 = RDIMS_VIS_COMP_1
        rdim2 = RDIMS_VIS_COMP_2

        if rdims_vis_method == "tsne":
            rdims_table = infile.replace(
                "sentinel", str(PARAMS["tsne_perplexity"]) + ".txt")
        elif rdims_vis_method == "umap":
            rdims_table = infile.replace(
                ".sentinel", ".txt")

        if(d.shape[0] > 0):

            if PARAMS["plot_shape"] != "":
                shape = "--shapefactor=%(plot_shape)s" % PARAMS
            else:
                shape = ""

            statement = '''Rscript %(tenx_dir)s/R/plot_rdims_gene.R
                           --method=%(rdims_vis_method)s
                           --table=%(rdims_table)s
                           --seuratobject=%(seurat_object)s
                           --seuratassay=RNA
                           --rdim1=%(rdim1)s
                           --rdim2=%(rdim2)s
                           %(shape)s
                           --genetable=%(markers_file)s
                           --pointsize=%(plot_pointsize)s
                           --pointalpha=%(plot_pointalpha)s
                           --outdir=%(outdir)s
                           --plotdirvar=clusterMarkerRdimsPlotsDir
                           &> %(log_file)s
                       '''
            P.run(statement)

        else:
            with(open(os.path.join(outdir, "plot.rdims.genes.top." + name +
                                   ".cluster.markers.tex"), "w")) as tex:

                tex.write("No marker genes passed criteria for plotting\n")

    # keep up to n entries per cluster
    # note that groupby preserves the ordering.
    positive_markers = data[data["avg_logFC"] > 0]
    positive_markers = _filterAndScore(positive_markers)
    positive_markers = _skimMarkers(positive_markers,
                                    PARAMS["exprsreport_n_positive"])
    positive_markers["type"] = "+ve"
    positive_markers = _addGeneName(positive_markers)
    _report(positive_markers, "positive")

    negative_markers = data[data["avg_logFC"] < 0]
    negative_markers = _filterAndScore(negative_markers)
    negative_markers = _skimMarkers(negative_markers,
                                    PARAMS["exprsreport_n_negative"])
    negative_markers["type"] = "-ve"
    negative_markers = _addGeneName(negative_markers)
    _report(negative_markers, "negative")

    IOTools.touch_file(outfile)


# ########################################################################### #
# ################# Within cluster between condition DE ##################### #
# ########################################################################### #

# Here genes differentially expressed between two conditions are identified
# at the cluster level.
#
# This analysis is optional.
#
# It is only run on samples prefixed with "all.", "agg." or "aligned."

@active_if(PARAMS["findmarkers_between"])
@follows(getGenesetAnnotations)
@transform(cluster,
           regex(r"(all.*|agg.*|aligned.*|integrated.*)/cluster.dir/cluster.sentinel"),
           r"\1/condition.markers.dir/findMarkersBetweenConditions.sentinel")
def findMarkersBetweenConditions(infile, outfile):
    '''
    Identification of genes differentially expressed within-cluster.

    The two conditions to compare must be specified in the configuration file.

    This analysis is run in parallel for each cluster.
    '''

    indir = os.path.dirname(infile)
    outdir = os.path.dirname(outfile)

    cluster_ids = infile.replace(".sentinel", "_ids.rds")

    clusters = pd.read_table(os.path.join(indir, "cluster_ids.txt"),
                            header=None)
    clusters = clusters[clusters.columns[0]].tolist()
    nclusters = len(clusters)

    seurat_object = os.path.join(Path(outdir).parents[1],
                                 "begin.rds")

    components, resolution, algorithm, test = outdir.split(
        "/")[-2].split("_")

    threshuse = PARAMS["findmarkers_threshuse"]
    minpct = PARAMS["findmarkers_minpct"]

    job_memory = PARAMS["resources_memory_standard"]

    statements = []

    # need to generalise this...
    group_a = PARAMS["findmarkers_between_a"]
    group_b = PARAMS["findmarkers_between_b"]
    tenx_dir = PARAMS["tenx_dir"]
    testfactor = PARAMS["findmarkers_between_testfactor"]

    if PARAMS["findmarkers_conserved_between"]:
        conservedfactor = PARAMS["findmarkers_conserved_between_factor"]
        conservedpadj = PARAMS["findmarkers_conserved_between_padj"]
        conserved_options = '''--conservedfactor=%(conservedfactor)s
            --conservedpadj=%(conservedpadj)s
        '''
    else:
        conserved_options = ""

    for i in range(min(clusters), max(clusters)+1):

        logfile = outfile.replace(".sentinel", "." + str(i) + ".log")
        statements.append('''Rscript %(tenx_dir)s/R/seurat_FindMarkers.R
                   --seuratobject=%(seurat_object)s
                   --seuratassay=RNA
                   --clusterids=%(cluster_ids)s
                   --cluster=%(i)s
                   --testfactor=%(testfactor)s
                   --a=%(group_a)s
                   --b=%(group_b)s
                   --testuse=%(test)s
                   --threshuse=%(threshuse)s
                   --minpct=%(minpct)s
                   --mindiffpct=-Inf
                   --annotation=annotation.dir/ensembl.to.entrez.txt.gz
                   %(conserved_options)s
                   --outdir=%(outdir)s
                   &> %(logfile)s
                ''' % locals())

    P.run(statements)

    IOTools.touch_file(outfile)


@active_if(PARAMS["findmarkers_between"])
@transform(findMarkersBetweenConditions,
           regex(r"(.*)/findMarkersBetweenConditions.sentinel"),
           r"\1/summariseMarkersBetweenConditions.sentinel")
def summariseMarkersBetweenConditions(infile, outfile):
    '''
    Make summary tables and plots of within-cluster DE genes.

    The per-cluster results files are aggregated. A heatmap of the top
    cluster markers is generated. A summary excel file is generated.
    Tables for geneset enrichment testing are prepared.
    '''

    outdir = os.path.dirname(outfile)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    seurat_object = os.path.join(Path(outdir).parents[1],
                               "begin.rds")

    job_memory = PARAMS["resources_memory_standard"]

    testname = os.path.basename(outfile).split(".")[1]

    log_file = outfile.replace(".sentinel", ".log")

    # make sumamary tables and plots of the differentially expressed genes
    statement = '''Rscript %(tenx_dir)s/R/seurat_summariseMarkersBetween.R
                   --seuratobject=%(seurat_object)s
                   --seuratassay=RNA
                   --testfactor=%(findmarkers_between_testfactor)s
                   --a=%(findmarkers_between_a)s
                   --b=%(findmarkers_between_b)s
                   --clusterids=%(cluster_ids)s
                   --outdir=%(outdir)s
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


@active_if(PARAMS["findmarkers_between"])
@transform(summariseMarkersBetweenConditions,
           regex(r"(.*)/condition.markers.dir/summariseMarkersBetweenConditions.sentinel"),
           r"\1/condition.marker.de.plots.dir/characteriseClusterMarkersBetween.tex")
def characteriseClusterMarkersBetweenConditions(infile, outfile):
    '''
    Characterise within-cluster DE genes.

    Diagnostic summary plots of differentially expressed genes
    and violin plots are generated.

    Parallelised per-cluster.
    '''

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.between." +
                                PARAMS["findmarkers_between_testfactor"] +
                                ".summary.table.txt.gz")

    outdir = os.path.dirname(outfile)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    seurat_object = os.path.join(Path(outdir).parents[1],
                               "begin.rds")

    job_memory = PARAMS["resources_memory_low"]

    # not all clusters may have degenes
    degenes = pd.read_csv(marker_table, sep="\t")
    clusters = [x for x in set(degenes["cluster"].values)]

    tenx_dir = PARAMS["tenx_dir"]
    testfactor = PARAMS["findmarkers_between_testfactor"]
    a = PARAMS["findmarkers_between_a"]
    b = PARAMS["findmarkers_between_b"]

    statements = []
    tex = []
    for i in clusters:

        log_file = outfile[:-len(".tex")] + "." + str(i) + ".log"

        statement = '''
                    Rscript %(tenx_dir)s/R/seurat_characteriseClusterDEGenes.R
                    --degenes=%(marker_table)s
                    --seuratobject=%(seurat_object)s
                    --seuratassay=RNA
                    --clusterids=%(cluster_ids)s
                    --cluster=%(i)s
                    --testfactor=%(testfactor)s
                    --a=%(a)s
                    --b=%(b)s
                    --useminfc=FALSE
                    --outdir=%(outdir)s
                    --plotdirvar=conditionMarkerDEPlotsDir
                    &> %(log_file)s
                    ''' % locals()

        cluster_tex_file = ".".join(["characterise.degenes", str(i),
                                     "between.tex"])

        tex.append("\\input{\\conditionMarkerDEPlotsDir/" + cluster_tex_file + "}")
        statements.append(statement)

    P.run(statements)

    with open(outfile, "w") as out_tex:
        for line in tex:
            out_tex.write(line + "\n")


@active_if(PARAMS["findmarkers_between"])
@transform(summariseMarkersBetweenConditions,
           regex(r"(.*)/condition.markers.dir/(.*).sentinel"),
           r"\1/condition.marker.de.plots.dir/plotMarkerNumbersBetween.sentinel")
def plotMarkerNumbersBetweenConditions(infile, outfile):
    '''
    Summarise the numbers of within-cluster DE genes.
    '''

    marker_table = os.path.join(os.path.dirname(infile),
                                "markers.between." +
                                PARAMS["findmarkers_between_testfactor"] +
                                ".summary.table.txt.gz")

    outdir = os.path.dirname(outfile)

    cluster_ids = os.path.join(Path(outdir).parents[0],
                               "cluster.dir",
                               "cluster_ids.rds")

    job_memory = PARAMS["resources_memory_low"]

    log_file = outfile.replace(".sentinel", ".log")

    statement = '''Rscript %(tenx_dir)s/R/seurat_summariseMarkerNumbers.R
                   --degenes=%(marker_table)s
                   --clusterids=%(cluster_ids)s
                   --testfactor=%(findmarkers_between_testfactor)s
                   --a=%(findmarkers_between_a)s
                   --b=%(findmarkers_between_b)s
                   --minfc=2
                   --minpadj=0.05
                   --outdir=%(outdir)s
                   --plotdirvar=conditionMarkerDEPlotsDir
                   &> %(log_file)s
                '''

    P.run(statement)

    IOTools.touch_file(outfile)


# ########################################################################### #
# ########### marker gene (and within cluster DE) analysis ################## #
# ########################################################################### #

@follows(characteriseClusterMarkers,
         plotMarkerNumbers,
         characteriseClusterMarkersBetweenConditions,
         plotMarkerNumbersBetweenConditions)
def markers():
    pass


# ########################################################################### #
# ######################### Geneset Analysis ################################ #
# ########################################################################### #

def parseGMTs(param_keys=["gmt_pathway_files_"]):
    '''Helper function for parsing the lists of GMT files'''

    all_files = []
    all_names = []

    for param_key in param_keys:


        gmts = [x for x in PARAMS.keys()
                if x.startswith(param_key)]

        if len(gmts) > 0:
            all_files += [PARAMS[x] for x in gmts]

            all_names += [x.replace(param_key, "")
                              for x in gmts]

    if len(all_files) == 0:
        all_files = "none"
        all_names = "none"
    else:
        all_files = ",".join(all_files)
        all_names = ",".join(all_names)

    return all_names, all_files


# ------------------- < between cluster geneset analysis > ------------------ #

@active_if(PARAMS["genesets_active"])
@follows(summariseMarkers)
@transform(findMarkers,
           regex(r"(.*)/cluster.markers.dir/.*.sentinel"),
           add_inputs(getGenesetAnnotations),
           r"\1/cluster.genesets.dir/geneset.analysis.sentinel")
def genesetAnalysis(infiles, outfile):
    '''
    Naive geneset over-enrichment analysis of cluster marker genes.

    Testing is performed with the gsfisher package.

    GO categories and KEGG pathways are tested by default.

    Arbitrary sets of genes cat be supplied as GMT files
    (e.g. such as those from MSigDB).
    '''

    findMarkersLog, genesetAnno = infiles

    indir = os.path.dirname(findMarkersLog)

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.mkdir(outdir)


    anno = os.path.join(os.path.dirname(genesetAnno),
                        "ensembl.to.entrez.txt.gz")

    kegg_pathways = os.path.join(os.path.dirname(genesetAnno),
                                 "kegg_pathways.rds")

    param_keys = ["gmt_celltype_files_",
                  "gmt_pathway_files_"]
    gmt_names, gmt_files = parseGMTs(param_keys=param_keys)

    clusters = pd.read_table(os.path.join(Path(outdir).parents[0],
                           "cluster.dir",
                           "cluster_ids.txt"),
                            header=None)
    clusters = clusters[clusters.columns[0]].tolist()
    nclusters = len(clusters)

    job_memory = PARAMS["resources_memory_standard"]

    statements = []

    species = PARAMS["annotation_species"]
    tenx_dir = PARAMS["tenx_dir"]

    adjpthreshold = PARAMS["genesets_marker_adjpthreshold"]

    for i in range(min(clusters), max(clusters)+1):

        logfile = os.path.join(outdir, "geneset.analysis." + str(i) + ".log")

        markers = os.path.join(indir, "markers.summary.table.txt.gz")

        universe = os.path.join(
            indir, "markers.cluster." + str(i) + ".universe.txt.gz")

        if not os.path.exists(universe):
            E.warn("Skipping geneset analysis: %s does not exist" % universe)
            continue

        statements.append('''Rscript %(tenx_dir)s/R/genesetAnalysis.R
                            --markers=%(markers)s
                            --universe=%(universe)s
                            --species=%(species)s
                            --annotation=%(anno)s
                            --kegg_pathways=%(kegg_pathways)s
                            --gmt_names=%(gmt_names)s
                            --gmt_files=%(gmt_files)s
                            --cluster=%(i)s
                            --adjpthreshold=%(adjpthreshold)s
                            --direction=positive
                            --outdir=%(outdir)s
                            &> %(logfile)s
                      ''' % locals())

    P.run(statements)

    IOTools.touch_file(outfile)

@active_if(PARAMS["genesets_active"])
@transform(genesetAnalysis,
           regex(r"(.*)/.*.sentinel"),
           r"\1/summarise.geneset.analysis.sentinel")
def summariseGenesetAnalysis(infile, outfile):
    '''
    Summarise the geneset over-enrichment analyses of cluster marker genes.

    Enriched pathways are summarised in an Excel table and a heatmap.
    '''

    outdir = os.path.dirname(outfile)

    # need to sort out the dependencies properly!
    genesetdir = os.path.dirname(infile)

    param_keys = ["gmt_celltype_files_",
                  "gmt_pathway_files_"]
    gmt_names, gmt_files = parseGMTs(param_keys=param_keys)

    # Read clusters
    clusters = pd.read_table(os.path.join(Path(outdir).parents[0],
                           "cluster.dir",
                           "cluster_ids.txt"),
                            header=None)
    clusters = clusters[clusters.columns[0]].tolist()
    nclusters = len(clusters)
    firstcluster = min(clusters)

    # Read job memory parameter
    job_memory = PARAMS["resources_memory_standard"]

    logfile = outfile.replace(".sentinel", ".log")

    use_adjusted = str(PARAMS["genesets_use_adjusted_pvalues"]).upper()
    show_common = str(PARAMS["genesets_show_common"]).upper()

    show_detailed = str(PARAMS["genesets_show_detailed"])

    statement = '''Rscript %(tenx_dir)s/R/summariseGenesets.R
                         --genesetdir=%(genesetdir)s
                         --gmt_names=%(gmt_names)s
                         --show_detailed=%(show_detailed)s
                         --nclusters=%(nclusters)s
                         --firstcluster=%(firstcluster)s
                         --mingenes=%(genesets_min_fg_genes)s
                         --pvaluethreshold=%(genesets_pvalue_threshold)s
                         --padjustmethod=%(genesets_padjust_method)s
                         --useadjusted=%(use_adjusted)s
                         --minoddsratio=%(genesets_min_odds_ratio)s
                         --showcommon=%(show_common)s
                         --outprefix=%(outdir)s/cluster.genesets
                         --prefix=genesets
                         --plotdirvar=clusterGenesetsDir
                    &> %(logfile)s
                      '''
    P.run(statement)

    IOTools.touch_file(outfile)


# ------------------- < within cluster geneset analysis > ------------------- #

@active_if(PARAMS["genesets_active"])
@active_if(PARAMS["findmarkers_between"])
@follows(summariseMarkersBetweenConditions)
@transform(findMarkersBetweenConditions,
           regex(r"(.*)/condition.markers.dir/.*.sentinel"),
           add_inputs(getGenesetAnnotations),
           r"\1/condition.genesets.dir/geneset.analysis.between.conditions.sentinel")
def genesetAnalysisBetweenConditions(infiles, outfile):
    '''
    Naive geneset over-enrichment analysis of genes DE within-cluster.

    Testing is performed with the gsfisher package.

    GO categories and KEGG pathways are tested by default.

    Arbitrary sets of genes cat be supplied as GMT files
    (e.g. such as those from MSigDB).
    '''

    findMarkersLog, genesetAnno = infiles

    indir = os.path.dirname(findMarkersLog)

    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.mkdir(outdir)

    anno = os.path.join(os.path.dirname(genesetAnno),
                        "ensembl.to.entrez.txt.gz")

    kegg_pathways = os.path.join(os.path.dirname(genesetAnno),
                                 "kegg_pathways.rds")


    gmt_names, gmt_files = parseGMTs(param_keys=["gmt_pathway_files_"])

    # Read custers
    clusters = pd.read_table(os.path.join(Path(outdir).parents[0],
                           "cluster.dir",
                           "cluster_ids.txt"),
                            header=None)
    clusters = clusters[clusters.columns[0]].tolist()
    nclusters = len(clusters)

    # Read job memory params
    job_memory = PARAMS["resources_memory_standard"]

    statements = []

    species = PARAMS["annotation_species"]
    tenx_dir = PARAMS["tenx_dir"]

    adjpthreshold = PARAMS["genesets_marker_adjpthreshold"]

    for i in range(min(clusters), max(clusters)+1):

        logfile = os.path.join(
            outdir, "geneset.analysis.between." + str(i) + ".log")

        markers = os.path.join(
            indir, "markers.between." +
            PARAMS["findmarkers_between_testfactor"] +
            ".summary.table.txt.gz")

        universe = os.path.join(
            indir, "markers.between." +
            PARAMS["findmarkers_between_testfactor"] +
            ".cluster." + str(i) + ".universe.txt.gz")

        if not os.path.exists(universe):
            E.warn("Skipping geneset analysis: %s does not exist" % universe)
            continue

        statements.append('''Rscript %(tenx_dir)s/R/genesetAnalysis.R
                            --markers=%(markers)s
                            --universe=%(universe)s
                            --species=%(species)s
                            --annotation=%(anno)s
                            --kegg_pathways=%(kegg_pathways)s
                            --gmt_names=%(gmt_names)s
                            --gmt_files=%(gmt_files)s
                            --cluster=%(i)s
                            --adjpthreshold=%(adjpthreshold)s
                            --direction=both
                            --prefix=genesets.between
                            --outdir=%(outdir)s
                            &> %(logfile)s
                      ''' % locals())

    P.run(statements)

    IOTools.touch_file(outfile)

@active_if(PARAMS["genesets_active"])
@active_if(PARAMS["findmarkers_between"])
@transform(genesetAnalysisBetweenConditions,
           regex(r"(.*)/.*.sentinel"),
           r"\1/summarise.geneset.analysis.between.conditions.sentinel")
def summariseGenesetAnalysisBetweenConditions(infile, outfile):
    '''
    Summarise the geneset over-enrichment analyses of genes DE within-cluster.

    Enriched pathways are summarised in an Excel table and a heatmap.
    '''

    outdir = os.path.dirname(outfile)

    genesetdir = os.path.dirname(infile)

    # Read clusters
    clusters = pd.read_table(os.path.join(Path(outdir).parents[0],
                           "cluster.dir",
                           "cluster_ids.txt"),
                            header=None)
    clusters = clusters[clusters.columns[0]].tolist()
    nclusters = len(clusters)
    firstcluster = min(clusters)

    # Read memory params
    job_memory = PARAMS["resources_memory_standard"]


    logfile = outfile.replace(".sentinel", ".log")

    gmt_names, gmt_files = parseGMTs(param_keys=["gmt_pathway_files_"])

    use_adjusted = str(PARAMS["genesets_use_adjusted_pvalues"]).upper()
    show_common = str(PARAMS["genesets_show_common"]).upper()

    show_detailed = str(PARAMS["genesets_show_detailed"])

    statement = '''Rscript %(tenx_dir)s/R/summariseGenesets.R
                         --genesetdir=%(genesetdir)s
                         --gmt_names=%(gmt_names)s
                         --show_detailed=%(show_detailed)s
                         --nclusters=%(nclusters)s
                         --firstcluster=%(firstcluster)s
                         --mingenes=%(genesets_min_fg_genes)s
                         --pvaluethreshold=%(genesets_pvalue_threshold)s
                         --padjustmethod=%(genesets_padjust_method)s
                         --minoddsratio=%(genesets_min_odds_ratio)s
                         --useadjusted=%(use_adjusted)s
                         --showcommon=%(show_common)s
                         --outprefix=%(outdir)s/condition.genesets
                         --prefix=genesets.between
                         --plotdirvar=conditionGenesetsDir
                    &> %(logfile)s
                      '''

    P.run(statement)

    IOTools.touch_file(outfile)

# ---------------------- < geneset analysis target > ---------------------- #

@follows(summariseGenesetAnalysis,
         summariseGenesetAnalysisBetweenConditions)
def genesets():
    pass


# ########################################################################### #
# ##################### Target to collect plots ############################# #
# ########################################################################### #

@follows(clustree,
         paga,
         plotTSNEPerplexities,
         plotRdimsFactors,
         plotRdimsGenes,
         plotRdimsMarkers,
         diffusionMap,
         plotGroupNumbers,
         scvelo,
         knownMarkerViolins)
def plots():
    '''
    Intermediate target to collect plots.
    '''

    pass


# ########################################################################### #
# ################## PDF report generation (via Latex) ###################### #
# ########################################################################### #

# High quality pdf reports are generated which can be easily shared.
#
# The reports incorporate raster (png) graphics. PDF versions of each graphic
# are also avaliable in the individual run folders.

@follows(markers,
         genesets,
         plots,
         summariseGenesetAnalysis)
@transform(plotRdimsFactors,
           regex("(.*)/rdims.visualisation.dir/plot.rdims.factor.sentinel"),
           r"\1/latex.dir/report.vars.sty")
def latexVars(infile, outfile):
    '''
    Prepare a file containing the latex variable definitions.
    '''

    outdir = os.path.dirname(outfile)

    if not os.path.exists(outdir):
        os.mkdir(outdir)

    runDir = Path(outdir).parents[0]

    outfile_name = os.path.basename(outfile)

    clusterDir = os.path.join(runDir,
                              "cluster.dir")

    clusterGenesetsDir = os.path.join(runDir,
                              "cluster.genesets.dir")

    clusterMarkerDEPlotsDir = os.path.join(runDir,
                              "cluster.marker.de.plots.dir")

    clusterMarkerRdimsPlotsDir = os.path.join(runDir,
                                             "cluster.marker.rdims" +\
                                             ".plots.dir")

    clusterMarkersDir = os.path.join(runDir,
                                     "cluster.markers.dir")

    conditionGenesetsDir = os.path.join(runDir,
                              "condition.genesets.dir")

    conditionMarkerDEPlotsDir = os.path.join(runDir,
                              "condition.marker.de.plots.dir")

    conditionMarkerTSNEPlotsDir = os.path.join(runDir,
                                             "condition.marker.tsne.plots.dir")

    conditionMarkersDir = os.path.join(runDir,
                                     "condition.markers.dir")

    genelistsDir = os.path.join(runDir,
                                "genelists.dir")

    knownmarkersDir = os.path.join(runDir,
                                   "known.markers.dir")

    diffmapDir = os.path.join(runDir,
                              "diffusionmap.dir")

    groupNumbersDir = os.path.join(runDir,
                                   "group.numbers.dir")

    tsneDir = os.path.join(runDir,
                           "tsne.dir")

    umapDir = os.path.join(runDir,
                           "umap.dir")

    rdimsVisDir = os.path.join(runDir,
                               "rdims.visualisation.dir")

    rdimsVisMethod = RDIMS_VIS_METHOD

    velocityDir = os.path.join(runDir,
                               "velocity.dir")

    pagaDir = os.path.join(runDir,
                               "paga.dir")

    # runDir is the directory containing the begin.rds object.
    sampleDir = Path(outdir).parents[1]

    runDirBaseName = os.path.basename(runDir)

    nPCs, resolution, algorithm, deTest = runDirBaseName.split("_")

    runName = runDirBaseName.replace("_", "\\_")

    runDetails = ("no. components: " + str(nPCs) +
                  ", cluster resolution: " + str(resolution) +
                  ", cluster algorithm: " + str(algorithm) +
                  ", de test: " + deTest)

    reductionType = PARAMS["dimreduction_method"]

    sample = Path(outfile).parts[0].split(".")[0]
    jobName = sample + "_" + runName.replace(".cluster.dir", "")

    sample = sample.replace("_", "\\_")

    latentvars = PARAMS["regress_latentvars"].replace("_", "\\_")

    if PARAMS["findmarkers_conserved"]:
        conservedFactor = PARAMS["findmarkers_conserved_factor"]
        conservedFactor = conservedFactor.replace("_", "\\_")
    else:
        conservedFactor = "None"

    if PARAMS["findmarkers_conserved_between"]:
        conservedBetweenFactor = PARAMS["findmarkers_conserved_between_factor"]
        conservedBetweenFactor = conservedBetweenFactor.replace("_", "\\_")
    else:
        conservedBetweenFactor = "None"

    if PARAMS["normalization_method"] == "log-normalization":
        varGeneMethod = PARAMS["vargenes_method"]
    elif PARAMS["normalization_method"] == "sctransform":
        varGeneMethod = "SCTransform"
    else:
        raise ValueError("unrecognised normalization method")

    vars = {"sample": "%(sample)s" % locals(),
            "projectName": "%(projectname)s" % PARAMS,
            "reportAuthor": "%(author)s" % PARAMS,
            "runDir": "%(runDir)s" % locals(),
            "sampleDir": "%(sampleDir)s" % locals(),
            "clusterDir": "%(clusterDir)s" % locals(),
            "tsneDir": "%(tsneDir)s" % locals(),
            "clusterGenesetsDir": "%(clusterGenesetsDir)s" % locals(),
            "clusterMarkerDEPlotsDir": "%(clusterMarkerDEPlotsDir)s" % locals(),
            "clusterMarkerRdimsPlotsDir": "%(clusterMarkerRdimsPlotsDir)s" % locals(),
            "clusterMarkersDir": "%(clusterMarkersDir)s" % locals(),
            "conditionGenesetsDir": "%(conditionGenesetsDir)s" % locals(),
            "conditionMarkerDEPlotsDir": "%(conditionMarkerDEPlotsDir)s" % locals(),
            "conditionMarkersDir": "%(conditionMarkersDir)s" % locals(),
            "knownmarkersDir": "%(knownmarkersDir)s" % locals(),
            "genelistsDir": "%(genelistsDir)s" % locals(),
            "diffmapDir": "%(diffmapDir)s" % locals(),
            "groupNumbersDir": "%(groupNumbersDir)s" % locals(),
            "umapDir": "%(umapDir)s" % locals(),
            "rdimsVisDir": "%(rdimsVisDir)s" % locals(),
            "rdimsVisMethod": "%(rdimsVisMethod)s" % locals() ,
            "velocityDir": "%(velocityDir)s" % locals(),
            "pagaDir": "%(pagaDir)s" % locals(),
            "runName": "%(runName)s" % locals(),
            "runDetails": "%(runDetails)s" % locals(),
            "tenxDir": "%(tenx_dir)s" % PARAMS,
            "nPCs": "%(nPCs)s" % locals(),
            "normalizationMethod": "%(normalization_method)s" % PARAMS,
            "reductionType": "%(reductionType)s" % locals(),
            "tSNEPerplexity": "%(tsne_perplexity)s" % PARAMS,
            "tSNEMaxIter": "%(tsne_maxiter)s" % PARAMS,
            "tSNEFast": "%(tsne_fast)s" % PARAMS,
            "nPositiveMarkers": "%(exprsreport_n_positive)s" % PARAMS,
            "nNegativeMarkers": "%(exprsreport_n_negative)s" % PARAMS,
            "resolution": "%(resolution)s" % locals(),
            "clusteringAlgorithm": "%(algorithm)s" % locals(),
            "deTest": "%(deTest)s" % locals(),
            "threshUse": "%(findmarkers_threshuse)s" % PARAMS,
            "minPct": "%(findmarkers_minpct)s" % PARAMS,
            "qcMinGenes": "%(qc_mingenes)s" % PARAMS,
            "qcMaxMito": "%(qc_maxpercentmito)s" % PARAMS,
            "minCells": "%(qc_mincells)s" % PARAMS,
            "modelType": "%(regress_modeluse)s" % PARAMS,
            "latentVariables": "%(latentvars)s" % locals(),
            "cellCycle": "%(regress_cellcycle)s" % PARAMS,
            "varGeneMethod": "%(varGeneMethod)s" % locals(),
            "sdCutOff": "%(vargenes_sdcutoff)s" % PARAMS,
            "conservedFactor": "%(conservedFactor)s" % locals(),
            "conservedBetweenFactor": "%(conservedBetweenFactor)s" % locals()}

    with open(outfile, "w") as ofh:
        for command, value in vars.items():

            ofh.write("\\newcommand{\\" + command + "}{" + value + "}\n")


@transform(latexVars,
           regex("(.*)/report.vars.sty"),
           r"\1/geneExpressionReport.pdf")
def geneExpressionReport(infile, outfile):
    '''
     Prepare a PDF report of the expression of genes interest.

     The expression of  manually specified sets of genes and of
     discovered cluster markers is visualised.
    '''

    outfile_name = os.path.basename(outfile)
    jobName = outfile_name[:-len(".pdf")]

    outdir = os.path.dirname(outfile)
    compilation_dir = os.path.join(outdir, ".latex_compilation.dir")

    latexVars = os.path.join(outdir, "report.vars")

    try:
        os.stat(compilation_dir)
    except FileNotFoundError:
        os.mkdir(compilation_dir)

    statement = '''pdflatex -output-directory=%(compilation_dir)s
                            -jobname=%(jobName)s
      '\\def\\latexVars{%(latexVars)s}
       \\def\\reportTitle{pipeline\\_seurat.py: gene expression report}
       \\input %(tenx_dir)s/pipelines/pipeline_seurat/geneExpressionReport.tex
       \\input %(tenx_dir)s/latex/endmatter.tex'
       '''

    # Deliberately run twice - necessary for LaTeX compilation..
    P.run(statement)
    P.run(statement)

    # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, outfile_name),
                outfile)


@transform(latexVars,
           regex("(.*)/report.vars.sty"),
           r"\1/summaryReport.pdf")
def summaryReport(infile, outfile):
    '''
    Prepare a PDF summary report.
    '''

    outfile_name = os.path.basename(outfile)
    jobName = outfile_name[:-len(".pdf")]

    outdir = os.path.dirname(outfile)
    rundir = Path(outdir).parents[0]

    compilation_dir = os.path.join(outdir, ".latex_compilation.dir")

    latexVars = os.path.join(outdir, "report.vars.sty")

    try:
        os.stat(compilation_dir)
    except FileNotFoundError:
        os.mkdir(compilation_dir)

    # get the latex variables
    statement = '''pdflatex -output-directory=%(compilation_dir)s
                            -jobname=%(jobName)s
      '\\input %(latexVars)s
       \\def\\reportTitle{pipeline\\_seurat.py: summary report}
                '''
    # get the intro
    statement += '''
      \\input %(tenx_dir)s/pipelines/pipeline_seurat/introReport.tex
      '''

    # begin the report (qc, hvg, pca dimension reduction)
    if(os.path.exists("data.dir")):
        statement += '''
          \\input %(tenx_dir)s/pipelines/pipeline_seurat/beginReport.tex
          '''

    # add the section with plots of cell and gene numbers etc.
    statement += '''
         \\input %(tenx_dir)s/pipelines/pipeline_seurat/numbersSection.tex
        '''

    # add the tSNE paramaeter analysis section
    statement += '''
         \\input %(tenx_dir)s/pipelines/pipeline_seurat/tsneSection.tex
        '''

    # add the section to visualise clusters and factors in reduced dimensions
    # (plots made by tsne or umap)
    statement += '''
         \\input %(tenx_dir)s/pipelines/pipeline_seurat/rdimsVisSection.tex
        '''

    statement += '''
      \\input %(tenx_dir)s/pipelines/pipeline_seurat/clusteringSection.tex
      '''

    if(PARAMS["diffusionmap_run"]):
        statement += '''
         \\input %(tenx_dir)s/pipelines/pipeline_seurat/diffusionSection.tex
        '''

    if(PARAMS["paga_run"]):
        statement += '''
         \\input %(tenx_dir)s/pipelines/pipeline_seurat/pagaSection.tex
        '''

    if(PARAMS["velocity_run"]):
        statement += '''
         \\input %(tenx_dir)s/pipelines/pipeline_seurat/scveloSection.tex
        '''

    if(PARAMS["knownmarkers_run"]):
        statement += '''
         \\input %(tenx_dir)s/pipelines/pipeline_seurat/knownmarkersSection.tex
        '''

    statement += '''
      \\input %(tenx_dir)s/pipelines/pipeline_seurat/markerReport.tex
      '''

    if(PARAMS["genesets_active"]):
        statement += '''
        \\input %(tenx_dir)s/pipelines/pipeline_seurat/genesetSection.tex
                     '''


    # When relevant, add section that compares
    # two conditions within each cluster
    if os.path.exists(
            os.path.join(rundir, "condition.markers.dir", "findMarkersBetweenConditions.sentinel")):

        wcc_section_name = "withinClusterComparisonSection.tex"
        statement += '''
          \\input %(tenx_dir)s/pipelines/pipeline_seurat/%(wcc_section_name)s
          '''

        if(PARAMS["genesets_active"]):
            statement += '''
        \\input %(tenx_dir)s/pipelines/pipeline_seurat/genesetBetweenSection.tex
                         '''


    statement += '''\\input %(tenx_dir)s/latex/endmatter.tex'
    '''

    # Deliberately run twice - necessary for LaTeX compilation..
    P.run(statement)
    P.run(statement)

    # Move the compiled pdfs to report.dir
    shutil.move(os.path.join(compilation_dir, outfile_name),
                outfile)


@follows(mkdir("reports.dir"), geneExpressionReport)
@transform(summaryReport,
           regex(r"(.*).seurat.dir/(.*)/latex.dir/summaryReport.pdf"),
           r"reports.dir/\1.\2/export.sentinel")
def export(infile, outfile):
    '''
    Link output files to a directory in the "reports.dir" folder.

    Prepare folders containing the reports, differentially expressed genes
    and geneset tables for each analysis.
    '''


    sample = Path(infile).parts[0].split(".")[0]

    cluster_run = Path(infile).parts[1]

    out_dir = os.path.join("reports.dir",
                           ".".join([sample, cluster_run]))

    run_dir = Path(os.path.dirname(infile)).parents[0]

    try:
        os.stat(out_dir)
    except FileNotFoundError:
        os.mkdir(out_dir)

    between_xlsx = "markers.between." + \
                   str(PARAMS["findmarkers_between_testfactor"]) + \
                   ".summary.table.xlsx"

    targets = [os.path.join(run_dir,"latex.dir","geneExpressionReport.pdf"),
               os.path.join(run_dir,"latex.dir","summaryReport.pdf"),
               os.path.join(run_dir,"cluster.markers.dir","markers.summary.table.xlsx"),
               os.path.join(run_dir,"condition.markers.dir",between_xlsx),
               os.path.join(run_dir, "cluster.genesets.dir","cluster.genesets.xlsx"),
               os.path.join(run_dir, "condition.genesets.dir","condition.genesets.xlsx")]

    for target_file in targets:


        if os.path.exists(target_file):

            target = os.path.basename(target_file)

            link_name = os.path.join(out_dir, target)

            os.symlink(os.path.relpath(target_file, start=out_dir),
                       link_name)

    IOTools.touch_file(outfile)

# ########################################################################### #
# ############## Generate cellbrowser output for sharing #################### #
# ########################################################################### #

@active_if(PARAMS["cellbrowser_run"])
@follows(mkdir("cellbrowser.dir"), summaryReport)
@transform("data.dir/*.dir",
           regex(r"data.dir/(.*).dir"),
           r"cellbrowser.dir/\1/cellbrowser.sentinel")
def cellbrowser(infile, outfile):
    '''
    Prepare cellbrowser instance for exploratory analysis or to share with
    collaborators. A cellbrowser instance is only generated for a defined
    runspecs configuration and only once per sample.'''

    # read in yml entries
    samples_specs = [s for s in PARAMS.keys()
                     if s.startswith("cellbrowser_")]
    samples_specs = [s for s in samples_specs if not "run" in s]

    # only run if sample ID from job is listed in yml
    sample_name = infile.split("/")[-1][:-len(".dir")]

    log_file = outfile.replace(".sentinel", ".log")
    outdir = os.path.dirname(outfile)
    if not os.path.exists(outdir):
        os.makedirs(outdir)

    # make cellbrowser if sample is mentioned in yml file
    if "cellbrowser_"+sample_name in samples_specs:
        settings_use = PARAMS[str("".join([k for k in samples_specs
                                           if str(sample_name) in k]))]
        outdir_settings = os.path.join(outdir, str(settings_use))
        # set up required subfolders
        if not os.path.exists(outdir_settings):
            os.makedirs(outdir_settings)
        # cellbrowser input files written into following folder
        outdir_folder = os.path.join(outdir_settings, "infiles")
        if not os.path.exists(outdir_folder):
            os.makedirs(outdir_folder)

        seurat_path = sample_name + ".seurat.dir"

        # Rscript to generate input files
        job_memory = PARAMS["resources_memory_standard"]
        statement = '''Rscript %(tenx_dir)s/R/cellbrowser_prep.R
                         --outdir=%(outdir_folder)s
                         --seurat_path=%(seurat_path)s
                         --runspecs=%(settings_use)s
                       &> %(log_file)s
                      '''
        P.run(statement)

        # python code to make configuration file
        out = open(os.path.join(outdir_settings, "cellbrowser.conf"), "w")
        conf = ""
        # cannot use projectname from pipeline.yml here as only letters/digits
        # allowed in name
        conf += 'name = "seuratPipeline"\n'
        conf += '''coords = [{"file":"infiles/UMAP.tsv","shortLabel":"UMAP"},
                             {"file":"infiles/FA.tsv","shortLabel":
                              "PAGA initiated force-directed graph"}]\n'''
        conf += 'shortLabel = "%s"\n' %PARAMS["projectname"]
        conf += 'exprMatrix = "infiles/exprMatrix.tsv.gz"\n'
        conf += 'meta = "infiles/meta.tsv"\n'
        conf += 'enumFields = ["cluster"]\n'
        conf += 'clusterField = "cluster"\n'
        conf += 'labelField = "cluster"\n'
        conf += 'colors = "infiles/colors.tsv"\n'
        conf += '''markers = [{"file": "infiles/markers.tsv",
                              "shortLabel": "Cluster markers identified by Seurat"}]\n'''
        out.write(conf)
        out.close()


        # python code to run cellbrowser
        cellbrowser_log = os.path.join(outdir_settings,
                                       "build_cb.log")
        cellbrowser_conf = os.path.join(outdir_settings, "cellbrowser.conf")
        outdir_cellbrowser = os.path.join(outdir_settings, "outfiles")
        statement = '''cbBuild -i %(cellbrowser_conf)s
                                -o %(outdir_cellbrowser)s
                                &> %(cellbrowser_log)s '''
        P.run(statement)

    else:
        # no cellbrowser for this sample
        statement = ''' echo "Do not generate cellbrowser"
                        > %(log_file)s '''
        P.run(statement)


    # add README to output folder
    readme_file = "cellbrowser.dir/README"
    if not os.path.exists(readme_file):
        statement = ''' echo "# to run cellbrowser, go to the chosen sample "
                        >> %(readme_file)s ;
                        echo "# folder (e.g. wildtype/30_0.8_1_wilcox) and use the "
                        >> %(readme_file)s ;
                        echo "# following command to open it on a port of your choice: "
                        >> %(readme_file)s ;
                        echo "cbBuild -i cellbrowser.init -o outfiles/ -p 8888"
                        >> %(readme_file)s  '''
        P.run(statement)

    IOTools.touch_file(outfile)





# --------------------------- < report target > ----------------------------- #

# This is the target normally used to execute the pipeline.

@follows(export, cellbrowser)
def report():
    pass


# ########################################################################### #
# ######################### Auxillary functions ############################# #
# ########################################################################### #

@transform(cluster,
           regex(r"(.*)/cluster.sentinel"),
           r"\1/cluster_counts.rds")
def aggregateUMIsPseudobulks(infile, outfile):
    '''
    Aggregate UMI counts across cells within cluster to form pseudobulks.

    Useful for performing e.g. DESeq2 analysis of clusters from
    multiple samples.
    '''

    outdir = os.path.dirname(infile)
    cluster_ids = os.path.join(outdir, "cluster_ids.rds")

    seurat_dir = Path(outfile).parents[1]
    sample_data_dir = str(seurat_dir).replace(".seurat", "")
    run_dir = Path(seurat_dir).parents[0]

    tenxdir = os.path.join(run_dir, 'data.dir', sample_data_dir)

    log_file = os.path.join(outdir, 'aggregated_clusters.log')

    job_memory = PARAMS["resources_memory_low"]

    statement = '''Rscript %(tenx_dir)s/R/aggregate_umis_pseudobulks.R
                           --tenxdir=%(tenxdir)s
                           --clusterids=%(cluster_ids)s
                           --outfile=%(outfile)s
                           &> %(log_file)s
                        '''

    P.run(statement)


# ------------------------ < auxillary target > ----------------------------- #

@follows(aggregateUMIsPseudobulks)
def aux():
    pass


# ########################################################################### #
# ##################### full target: to run all tasks ####################### #
# ########################################################################### #

@follows(report)
def full():
    pass


# ------------------- < ***** end of pipeline **** > ------------------------ #

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
